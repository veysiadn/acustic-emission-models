{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and USE GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 15:59:11.986613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 15:59:12.070938: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-12 15:59:12.087990: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 15:59:12.410595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 15:59:12.410635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 15:59:12.410639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 15:59:12.777576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:12.797305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:12.797442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:12.798052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 15:59:12.799013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:12.799107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:12.799161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:13.084133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:13.084257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:13.084340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 15:59:13.084394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19351 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# Using GPU\n",
    "import os\n",
    "import scipy.io as scpy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1000)\n",
      "(15000, 1)\n",
      " (12000, 1500, 1500)\n",
      " (12000, 1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# Using GPU\n",
    "import os\n",
    "import scipy.io as scpy\n",
    "\n",
    "data = scpy.loadmat(\"all-data.mat\")\n",
    "# Extracting x_train from the mat file dictionary.\n",
    "x_data = data[\"XTrain\"]\n",
    "# Extracting y_train from the mat file dictionary.\n",
    "y_data = data[\"y_train\"]\n",
    "# Converting x_train and y_train to a numpy array.\n",
    "x_data = np.array(x_data,dtype='float32')\n",
    "y_data = np.array(y_data,dtype='float32')-1\n",
    "x_temp_data=data['XTest']\n",
    "y_temp_data=data['y_test']\n",
    "x_temp_data=np.array(x_temp_data,dtype='float32')\n",
    "y_temp_data=np.array(y_temp_data,dtype='float32')-1\n",
    "# x_data=np.concatenate((x_data,x_temp_data),axis=0)\n",
    "# y_data=np.concatenate((y_data,y_temp_data),axis=0)\n",
    "\n",
    "# Verifying the shapes.\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# split into train test and validation sets\n",
    "x_train, x_val_to_use, y_train, y_val_to_use = train_test_split(x_data, y_data, test_size=0.2, random_state=SEED)\n",
    "x_val = x_val_to_use[:int(len(x_val_to_use)/2)]\n",
    "y_val = y_val_to_use[:int(len(y_val_to_use)/2)]\n",
    "x_test = x_val_to_use[int(len(x_val_to_use)/2):]\n",
    "y_test = y_val_to_use[int(len(y_val_to_use)/2):]\n",
    "print(f\" {len(x_train), len(x_val), len(x_test)}\")\n",
    "print(f\" {len(y_train), len(y_val), len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arange dataset in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dimension of train, test and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1500, 1500)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dense model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 4004      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,019\n",
      "Trainable params: 4,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.1398 - accuracy: 0.4277 - val_loss: 0.9400 - val_accuracy: 0.5287\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9051 - accuracy: 0.5549 - val_loss: 0.8220 - val_accuracy: 0.6140\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.8082 - accuracy: 0.6423 - val_loss: 0.7575 - val_accuracy: 0.6687\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.7500 - accuracy: 0.6888 - val_loss: 0.7138 - val_accuracy: 0.6973\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.7175 - val_loss: 0.6797 - val_accuracy: 0.7213\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.7377 - val_loss: 0.6510 - val_accuracy: 0.7407\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.6414 - accuracy: 0.7565 - val_loss: 0.6253 - val_accuracy: 0.7573\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.6140 - accuracy: 0.7697 - val_loss: 0.6014 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5886 - accuracy: 0.7837 - val_loss: 0.5784 - val_accuracy: 0.7853\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.7976 - val_loss: 0.5561 - val_accuracy: 0.7973\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.5412 - accuracy: 0.8126 - val_loss: 0.5347 - val_accuracy: 0.8133\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8230 - val_loss: 0.5143 - val_accuracy: 0.8240\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8339 - val_loss: 0.4949 - val_accuracy: 0.8347\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.8443 - val_loss: 0.4764 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8537 - val_loss: 0.4586 - val_accuracy: 0.8580\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8629 - val_loss: 0.4415 - val_accuracy: 0.8640\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8703 - val_loss: 0.4250 - val_accuracy: 0.8653\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8764 - val_loss: 0.4091 - val_accuracy: 0.8727\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8827 - val_loss: 0.3938 - val_accuracy: 0.8773\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8896 - val_loss: 0.3792 - val_accuracy: 0.8913\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8970 - val_loss: 0.3652 - val_accuracy: 0.9020\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.9042 - val_loss: 0.3518 - val_accuracy: 0.9053\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.9092 - val_loss: 0.3391 - val_accuracy: 0.9107\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.9132 - val_loss: 0.3270 - val_accuracy: 0.9127\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.9187 - val_loss: 0.3156 - val_accuracy: 0.9160\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.9224 - val_loss: 0.3047 - val_accuracy: 0.9220\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.9259 - val_loss: 0.2944 - val_accuracy: 0.9280\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9297 - val_loss: 0.2846 - val_accuracy: 0.9293\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2692 - accuracy: 0.9324 - val_loss: 0.2753 - val_accuracy: 0.9313\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9357 - val_loss: 0.2666 - val_accuracy: 0.9340\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9383 - val_loss: 0.2582 - val_accuracy: 0.9347\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9405 - val_loss: 0.2503 - val_accuracy: 0.9367\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9423 - val_loss: 0.2428 - val_accuracy: 0.9393\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9439 - val_loss: 0.2356 - val_accuracy: 0.9400\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9458 - val_loss: 0.2288 - val_accuracy: 0.9407\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9477 - val_loss: 0.2223 - val_accuracy: 0.9420\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9492 - val_loss: 0.2160 - val_accuracy: 0.9447\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2001 - accuracy: 0.9515 - val_loss: 0.2100 - val_accuracy: 0.9487\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9535 - val_loss: 0.2042 - val_accuracy: 0.9500\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9554 - val_loss: 0.1987 - val_accuracy: 0.9513\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9578 - val_loss: 0.1933 - val_accuracy: 0.9533\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9594 - val_loss: 0.1881 - val_accuracy: 0.9540\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9615 - val_loss: 0.1832 - val_accuracy: 0.9547\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9633 - val_loss: 0.1784 - val_accuracy: 0.9587\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9644 - val_loss: 0.1738 - val_accuracy: 0.9620\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9657 - val_loss: 0.1694 - val_accuracy: 0.9647\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9678 - val_loss: 0.1651 - val_accuracy: 0.9673\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9693 - val_loss: 0.1610 - val_accuracy: 0.9693\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9708 - val_loss: 0.1571 - val_accuracy: 0.9700\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9722 - val_loss: 0.1534 - val_accuracy: 0.9707\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9734 - val_loss: 0.1497 - val_accuracy: 0.9707\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9745 - val_loss: 0.1463 - val_accuracy: 0.9720\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9750 - val_loss: 0.1430 - val_accuracy: 0.9727\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1251 - accuracy: 0.9760 - val_loss: 0.1399 - val_accuracy: 0.9727\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9768 - val_loss: 0.1369 - val_accuracy: 0.9733\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9769 - val_loss: 0.1340 - val_accuracy: 0.9740\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9778 - val_loss: 0.1313 - val_accuracy: 0.9740\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9787 - val_loss: 0.1287 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9792 - val_loss: 0.1262 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9796 - val_loss: 0.1238 - val_accuracy: 0.9753\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9803 - val_loss: 0.1215 - val_accuracy: 0.9753\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9808 - val_loss: 0.1193 - val_accuracy: 0.9760\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9815 - val_loss: 0.1172 - val_accuracy: 0.9767\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9822 - val_loss: 0.1152 - val_accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9827 - val_loss: 0.1132 - val_accuracy: 0.9767\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9830 - val_loss: 0.1114 - val_accuracy: 0.9767\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9831 - val_loss: 0.1096 - val_accuracy: 0.9767\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9833 - val_loss: 0.1079 - val_accuracy: 0.9767\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9836 - val_loss: 0.1062 - val_accuracy: 0.9773\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9839 - val_loss: 0.1047 - val_accuracy: 0.9773\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9842 - val_loss: 0.1032 - val_accuracy: 0.9780\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9843 - val_loss: 0.1017 - val_accuracy: 0.9780\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9845 - val_loss: 0.1003 - val_accuracy: 0.9787\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9847 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9850 - val_loss: 0.0977 - val_accuracy: 0.9787\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9856 - val_loss: 0.0964 - val_accuracy: 0.9787\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9858 - val_loss: 0.0952 - val_accuracy: 0.9787\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9861 - val_loss: 0.0941 - val_accuracy: 0.9787\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 0.0930 - val_accuracy: 0.9787\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9871 - val_loss: 0.0919 - val_accuracy: 0.9787\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9873 - val_loss: 0.0909 - val_accuracy: 0.9787\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9878 - val_loss: 0.0899 - val_accuracy: 0.9793\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9880 - val_loss: 0.0889 - val_accuracy: 0.9793\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9881 - val_loss: 0.0880 - val_accuracy: 0.9793\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9884 - val_loss: 0.0871 - val_accuracy: 0.9793\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9885 - val_loss: 0.0863 - val_accuracy: 0.9793\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9886 - val_loss: 0.0854 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9887 - val_loss: 0.0847 - val_accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9887 - val_loss: 0.0839 - val_accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9889 - val_loss: 0.0831 - val_accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9892 - val_loss: 0.0824 - val_accuracy: 0.9807\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9892 - val_loss: 0.0817 - val_accuracy: 0.9807\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9893 - val_loss: 0.0811 - val_accuracy: 0.9807\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9896 - val_loss: 0.0804 - val_accuracy: 0.9807\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9897 - val_loss: 0.0798 - val_accuracy: 0.9813\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9899 - val_loss: 0.0792 - val_accuracy: 0.9820\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9901 - val_loss: 0.0786 - val_accuracy: 0.9827\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9902 - val_loss: 0.0780 - val_accuracy: 0.9827\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9902 - val_loss: 0.0775 - val_accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9904 - val_loss: 0.0770 - val_accuracy: 0.9840\n",
      "Training results\n",
      "Training Accuracy: 0.9904166460037231\n",
      "Training Loss: 0.05160150304436684\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.984000027179718\n",
      "Validation Loss: 0.0769500806927681\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "dense_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1000,)),\n",
    "    tf.keras.layers.Dense(4, activation='elu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "dense_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "dense_model.summary()              \n",
    "\n",
    "history=dense_model.fit(train_dataset,validation_data=val_dataset, epochs=100)\n",
    "# dense_model.evaluate(val_dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('dense_model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating dense_model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "Training Accuracy: 0.9904166460037231\n",
      "Training Loss: 0.05160150304436684\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.984000027179718\n",
      "Validation Loss: 0.0769500806927681\n"
     ]
    }
   ],
   "source": [
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating dense_model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dense model as tflite - no optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppcm7vyej/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppcm7vyej/assets\n",
      "2022-10-12 16:19:26.079545: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-12 16:19:26.079560: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-12 16:19:26.079637: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmppcm7vyej\n",
      "2022-10-12 16:19:26.080085: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-12 16:19:26.080094: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmppcm7vyej\n",
      "2022-10-12 16:19:26.081829: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-12 16:19:26.097989: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmppcm7vyej\n",
      "2022-10-12 16:19:26.101721: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 22083 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18220"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(dense_model)\n",
    "float_tflite_model = float_converter.convert()\n",
    "import pathlib\n",
    "tflite_model_file = pathlib.Path('dense_model.tflite')\n",
    "tflite_model_file.write_bytes(float_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i dense_model.tflite > dense_model.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize dense model and save it as tflite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsm4jy34r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsm4jy34r/assets\n",
      "/home/veysiadn/anaconda3/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-10-10 09:14:36.599325: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-10 09:14:36.599343: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-10 09:14:36.599439: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpsm4jy34r\n",
      "2022-10-10 09:14:36.599948: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-10 09:14:36.599960: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpsm4jy34r\n",
      "2022-10-10 09:14:36.601866: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-10 09:14:36.619246: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpsm4jy34r\n",
      "2022-10-10 09:14:36.622948: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 23508 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7048"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(dense_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "tflite_model_file = pathlib.Path('dense_model_optimized.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i dense_model_optimized.tflite > dense_model_optimized.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='dense_model.tflite')\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, indices):\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = 0\n",
    "  for i, index in enumerate(indices):\n",
    "    test_data = x_test[index]\n",
    "    test_data=np.expand_dims(test_data, axis=0)\n",
    "    test_labels = y_train[index]\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    print(output[0])\n",
    "    print(output[1])\n",
    "    print(output[2])\n",
    "    predictions = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.737704e-08\n",
      "0.00016263525\n",
      "0.99983716\n",
      " Model \n",
      " True:[2], Predicted:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "tflite_model_file = 'dense_model.tflite'\n",
    "# Change this to test a different image\n",
    "indice = 333\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, indice, model_type):\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [indice])\n",
    "\n",
    "  print(f\" Model \\n True:{y_test[indice]}, Predicted:{predictions}\")\n",
    "  \n",
    "test_model(tflite_model_file, indice, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_path='float_model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_tflite_model_for_eval(interpreter, indices):\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = 0\n",
    "  for i, index in enumerate(indices):\n",
    "    test_data = x_test_to_use[index]\n",
    "    test_data=np.expand_dims(test_data, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    predictions = output.argmax()\n",
    "  return predictions\n",
    "  \n",
    "def evaluate_model(interpreter):\n",
    "  output_predictions =[]\n",
    "  for i in range(len(x_test_to_use)):\n",
    "    output_predictions.append(run_tflite_model_for_eval(interpreter,[i]))\n",
    "  output_predictions = np.array(output_predictions)\n",
    "  output_predictions = np.expand_dims(output_predictions, axis=1)\n",
    "  accuracy = (output_predictions == y_test_to_use).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized dense_model TFLite test_accuracy: 0.9826666666666667\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='dense_model_optimized.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Optimized dense_model TFLite test_accuracy:', test_accuracy)\n",
    "# print('Quant TF test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with annotated layers for quantization -- Trial can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Quantization based training\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "# quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "# #### tf.keras.layers :\n",
    "\n",
    "# quantize_annotate_layer((tf.keras.layers.Reshape((1000,1,1),name='Reshape', input_shape=(1000,)))),\n",
    "# quantize_annotate_layer(tf.keras.layers.Conv2D(16,7,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Activation('relu')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(4,4,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Conv2D(8,5, padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Activation('relu')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(4,4,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(2,2,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Flatten()),\n",
    "# quantize_annotate_layer(tf.keras.layers.Dense(32)),\n",
    "# quantize_annotate_layer(tf.keras.layers.Dense(3, activation='softmax')),\n",
    "# ])\n",
    "# quantized_model = tfmot.quantization.keras.quantize_apply(model)\n",
    "# # quant_aware_model = tfmot.quantization.keras.quantize_model(base_model)\n",
    "# # quant_aware_model.summary()\n",
    "# print(model.summary())\n",
    "# quantized_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = quantized_model.fit(x_train, y_train ,epochs=50, validation_data=(x_test, y_test), verbose=1)   \n",
    "\n",
    "\n",
    "# # Plotting accuracy and loss\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "# plt.title('Model loss & accuracy')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# # accuracy!\n",
    "# print(\"Training results\")\n",
    "# print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
    "# print(f\"Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# # evaluating model\n",
    "# print(\"Evaluation results\")\n",
    "# print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "# print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41e74be16d15307d9f039f42bdba433d4433ec6233894682bf41214f89ea7b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
