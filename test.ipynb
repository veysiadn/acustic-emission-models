{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Veysi ADIN 19 SEPT 2022\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# Using GPU\n",
    "import os\n",
    "import scipy.io as scpy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV data, that is already converted from wav files in speech command dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10760/1926382603.py:13: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n",
      "/tmp/ipykernel_10760/1926382603.py:35: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n",
      "/tmp/ipykernel_10760/1926382603.py:56: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, os.path\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "num_of_samples = 3000\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_no_csv'\n",
    "filename_csv_no = np.zeros(num_of_samples)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_no = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_no_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_no[i][j] = rows[j][1]\n",
    "\n",
    "\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_yes_csv'\n",
    "filename_csv_no = np.zeros(num_of_samples)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_yes = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_yes_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_yes[i][j] = rows[j][1]\n",
    "\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_zero_csv'\n",
    "filename_csv_no = np.zeros(3000)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_zero = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_zero_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_zero[i][j] = rows[j][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shapes and prepare data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 16000)\n",
      "(3000, 16000)\n",
      "(3000, 16000)\n",
      "(9000, 16000)\n",
      "(9000, 1)\n",
      "(2086, 16000)\n",
      "(2089, 16000)\n",
      "(2125, 16000)\n"
     ]
    }
   ],
   "source": [
    "print(samples_no.shape)\n",
    "print(samples_yes.shape)\n",
    "print(samples_zero.shape)\n",
    "num_of_classes = 3 \n",
    "y_data = np.zeros((num_of_samples* num_of_classes,1))\n",
    "y_data[num_of_samples:2*num_of_samples] = 1\n",
    "y_data[2*num_of_samples:3*num_of_samples] = 2\n",
    "x_data = np.concatenate((samples_no,samples_yes,samples_zero),axis=0)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# split into train test sets\n",
    "x_train, x_val_to_use, y_train, y_val_to_use = train_test_split(x_data, y_data, test_size=0.3, random_state=SEED)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_to_use, y_val_to_use, test_size=0.5, random_state=SEED)\n",
    "\n",
    "\n",
    "class_num = 0\n",
    "class_indices = np.where(y_train == class_num)[0]\n",
    "class_data = x_train[class_indices]\n",
    "class_output = y_train[class_indices]\n",
    "print(class_data.shape)\n",
    "\n",
    "class_num = 1\n",
    "class_indices = np.where(y_train == class_num)[0]\n",
    "class_data = x_train[class_indices]\n",
    "class_output = y_train[class_indices]\n",
    "\n",
    "print(class_data.shape)\n",
    "class_num = 2\n",
    "class_indices = np.where(y_train == class_num)[0]\n",
    "class_data = x_train[class_indices]\n",
    "class_output = y_train[class_indices]\n",
    "print(class_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1350, 1350)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "dense_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(16000,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "dense_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-2),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "dense_model.summary()              \n",
    "\n",
    "history=dense_model.fit(x_train,y_train, validation_data=(x_val,y_val), epochs=100,verbose=1)\n",
    "# dense_model.evaluate(val_dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('dense_model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating dense_model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_17 (Conv1D)          (None, 15994, 32)         256       \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 15994, 32)         0         \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 1999, 32)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 1995, 48)          7728      \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1995, 48)          0         \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 498, 48)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 124, 48)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 5952)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 32)                190496    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199,635\n",
      "Trainable params: 199,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 234.9912 - accuracy: 0.5665 - val_loss: 141.0150 - val_accuracy: 0.6393\n",
      "Epoch 2/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 112.1458 - accuracy: 0.6754 - val_loss: 103.3132 - val_accuracy: 0.6993\n",
      "Epoch 3/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 71.8349 - accuracy: 0.7383 - val_loss: 75.2211 - val_accuracy: 0.7304\n",
      "Epoch 4/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 50.2009 - accuracy: 0.7654 - val_loss: 82.4833 - val_accuracy: 0.6978\n",
      "Epoch 5/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 40.6129 - accuracy: 0.7767 - val_loss: 59.6456 - val_accuracy: 0.7407\n",
      "Epoch 6/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 29.7758 - accuracy: 0.7967 - val_loss: 54.6207 - val_accuracy: 0.7378\n",
      "Epoch 7/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 22.8554 - accuracy: 0.8108 - val_loss: 43.6973 - val_accuracy: 0.7748\n",
      "Epoch 8/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 18.5405 - accuracy: 0.8210 - val_loss: 41.7118 - val_accuracy: 0.7763\n",
      "Epoch 9/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 14.2639 - accuracy: 0.8419 - val_loss: 45.2385 - val_accuracy: 0.7533\n",
      "Epoch 10/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 11.2755 - accuracy: 0.8533 - val_loss: 35.6523 - val_accuracy: 0.7807\n",
      "Epoch 11/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 9.9672 - accuracy: 0.8535 - val_loss: 34.6466 - val_accuracy: 0.7785\n",
      "Epoch 12/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 7.7966 - accuracy: 0.8748 - val_loss: 33.9895 - val_accuracy: 0.7770\n",
      "Epoch 13/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 7.2972 - accuracy: 0.8722 - val_loss: 29.3405 - val_accuracy: 0.7919\n",
      "Epoch 14/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 5.1628 - accuracy: 0.8889 - val_loss: 34.1720 - val_accuracy: 0.7770\n",
      "Epoch 15/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 6.7545 - accuracy: 0.8786 - val_loss: 31.0188 - val_accuracy: 0.7911\n",
      "Epoch 16/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 4.0142 - accuracy: 0.9059 - val_loss: 28.1371 - val_accuracy: 0.7904\n",
      "Epoch 17/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 2.8826 - accuracy: 0.9132 - val_loss: 27.7844 - val_accuracy: 0.7911\n",
      "Epoch 18/50\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 2.8134 - accuracy: 0.9157 - val_loss: 26.5689 - val_accuracy: 0.7881\n",
      "Epoch 19/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 2.5615 - accuracy: 0.9205 - val_loss: 26.3616 - val_accuracy: 0.7844\n",
      "Epoch 20/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 3.0448 - accuracy: 0.9160 - val_loss: 25.5466 - val_accuracy: 0.7852\n",
      "Epoch 21/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.8642 - accuracy: 0.9303 - val_loss: 27.2676 - val_accuracy: 0.7815\n",
      "Epoch 22/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.4690 - accuracy: 0.9340 - val_loss: 25.4439 - val_accuracy: 0.7970\n",
      "Epoch 23/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.4809 - accuracy: 0.9389 - val_loss: 25.5167 - val_accuracy: 0.7896\n",
      "Epoch 24/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.4729 - accuracy: 0.9367 - val_loss: 26.0594 - val_accuracy: 0.7630\n",
      "Epoch 25/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.3208 - accuracy: 0.9435 - val_loss: 25.3118 - val_accuracy: 0.7956\n",
      "Epoch 26/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 2.6177 - accuracy: 0.9241 - val_loss: 26.3047 - val_accuracy: 0.7844\n",
      "Epoch 27/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 2.2468 - accuracy: 0.9232 - val_loss: 22.5787 - val_accuracy: 0.8000\n",
      "Epoch 28/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.1247 - accuracy: 0.9489 - val_loss: 21.4563 - val_accuracy: 0.7874\n",
      "Epoch 29/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.0511 - accuracy: 0.9430 - val_loss: 21.4826 - val_accuracy: 0.8015\n",
      "Epoch 30/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.8822 - accuracy: 0.9552 - val_loss: 21.8035 - val_accuracy: 0.7778\n",
      "Epoch 31/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.6378 - accuracy: 0.9610 - val_loss: 18.6107 - val_accuracy: 0.8044\n",
      "Epoch 32/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.9708 - val_loss: 20.0218 - val_accuracy: 0.8007\n",
      "Epoch 33/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.5123 - accuracy: 0.9629 - val_loss: 19.7314 - val_accuracy: 0.8044\n",
      "Epoch 34/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.8729 - accuracy: 0.9548 - val_loss: 19.4050 - val_accuracy: 0.8081\n",
      "Epoch 35/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.0602 - accuracy: 0.9497 - val_loss: 18.7593 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.9610 - val_loss: 18.9840 - val_accuracy: 0.7963\n",
      "Epoch 37/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.7898 - accuracy: 0.9578 - val_loss: 18.3922 - val_accuracy: 0.7963\n",
      "Epoch 38/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.7006 - accuracy: 0.9624 - val_loss: 24.9713 - val_accuracy: 0.7859\n",
      "Epoch 39/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.0392 - accuracy: 0.9413 - val_loss: 18.8007 - val_accuracy: 0.7889\n",
      "Epoch 40/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.5858 - accuracy: 0.9614 - val_loss: 16.8693 - val_accuracy: 0.8015\n",
      "Epoch 41/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.7328 - accuracy: 0.9613 - val_loss: 21.5413 - val_accuracy: 0.7807\n",
      "Epoch 42/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 1.0381 - accuracy: 0.9498 - val_loss: 17.9285 - val_accuracy: 0.8015\n",
      "Epoch 43/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.5406 - accuracy: 0.9637 - val_loss: 18.2481 - val_accuracy: 0.7933\n",
      "Epoch 44/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.9741 - val_loss: 16.7640 - val_accuracy: 0.7963\n",
      "Epoch 45/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.4581 - accuracy: 0.9686 - val_loss: 16.4121 - val_accuracy: 0.8000\n",
      "Epoch 46/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.4800 - accuracy: 0.9624 - val_loss: 16.1920 - val_accuracy: 0.7844\n",
      "Epoch 47/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.1756 - accuracy: 0.9790 - val_loss: 16.0475 - val_accuracy: 0.7904\n",
      "Epoch 48/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9783 - val_loss: 16.6089 - val_accuracy: 0.7933\n",
      "Epoch 49/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9830 - val_loss: 15.3473 - val_accuracy: 0.8059\n",
      "Epoch 50/50\n",
      "197/197 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9889 - val_loss: 15.4802 - val_accuracy: 0.7985\n",
      "Training results\n",
      "Training Accuracy: 0.9888888597488403\n",
      "Training Loss: 0.11534957587718964\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.7985185384750366\n",
      "Validation Loss: 15.480188369750977\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(16000,1)))\n",
    "model.add(tf.keras.layers.Conv1D(32,7))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=8))\n",
    "model.add(tf.keras.layers.Conv1D(48,5))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train ,epochs=50, validation_data=(x_val, y_val), verbose=1)   \n",
    "\n",
    "\n",
    "# Plotting accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('Model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9882 - accuracy: 0.7133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9881768226623535, 0.7133333086967468]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 826us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "y_true = y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87456787"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scce = tf.keras.losses.MeanAbsoluteError()\n",
    "scce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_22 (Conv1D)          (None, 15992, 32)         320       \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 15992, 32)         0         \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 15986, 64)         14400     \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 15986, 64)         0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 15982, 256)        82176     \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 15982, 256)        0         \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 399, 256)         0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 44, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 11264)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 3)                 33795     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,691\n",
      "Trainable params: 130,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 22.7193 - accuracy: 0.5540 - val_loss: 10.6417 - val_accuracy: 0.6637\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 7.5348 - accuracy: 0.6844 - val_loss: 7.5410 - val_accuracy: 0.7022\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 4.6883 - accuracy: 0.7290 - val_loss: 4.6527 - val_accuracy: 0.7259\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 3.5602 - accuracy: 0.7462 - val_loss: 4.5870 - val_accuracy: 0.7289\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 2.9813 - accuracy: 0.7638 - val_loss: 3.3501 - val_accuracy: 0.7541\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 1.7883 - accuracy: 0.7946 - val_loss: 3.4319 - val_accuracy: 0.7407\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 1.4619 - accuracy: 0.8035 - val_loss: 2.7556 - val_accuracy: 0.7741\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 1.1318 - accuracy: 0.8190 - val_loss: 3.1344 - val_accuracy: 0.7148\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 1.1050 - accuracy: 0.8235 - val_loss: 2.7103 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.8347 - accuracy: 0.8376 - val_loss: 2.1727 - val_accuracy: 0.7756\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.7585 - accuracy: 0.8451 - val_loss: 1.9250 - val_accuracy: 0.8052\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.7158 - accuracy: 0.8470 - val_loss: 1.9599 - val_accuracy: 0.8052\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.6430 - accuracy: 0.8583 - val_loss: 1.8220 - val_accuracy: 0.8015\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.5745 - accuracy: 0.8652 - val_loss: 1.7709 - val_accuracy: 0.8089\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.5706 - accuracy: 0.8579 - val_loss: 1.8008 - val_accuracy: 0.8230\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3805 - accuracy: 0.8941 - val_loss: 1.7122 - val_accuracy: 0.8281\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3233 - accuracy: 0.9006 - val_loss: 1.5008 - val_accuracy: 0.8170\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3836 - accuracy: 0.8917 - val_loss: 1.5347 - val_accuracy: 0.8267\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3723 - accuracy: 0.8892 - val_loss: 1.5786 - val_accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3281 - accuracy: 0.9054 - val_loss: 1.6611 - val_accuracy: 0.7941\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3098 - accuracy: 0.9006 - val_loss: 1.5931 - val_accuracy: 0.8170\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3901 - accuracy: 0.8878 - val_loss: 1.6347 - val_accuracy: 0.8185\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.3556 - accuracy: 0.8910 - val_loss: 1.5944 - val_accuracy: 0.8296\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.3335 - accuracy: 0.9049 - val_loss: 1.5999 - val_accuracy: 0.8311\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2822 - accuracy: 0.9106 - val_loss: 1.4484 - val_accuracy: 0.8422\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2192 - accuracy: 0.9244 - val_loss: 1.4154 - val_accuracy: 0.8415\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2034 - accuracy: 0.9294 - val_loss: 1.4023 - val_accuracy: 0.8370\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 7s 38ms/step - loss: 0.2045 - accuracy: 0.9321 - val_loss: 1.7682 - val_accuracy: 0.8052\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 7s 38ms/step - loss: 0.2269 - accuracy: 0.9230 - val_loss: 1.4155 - val_accuracy: 0.8267\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2464 - accuracy: 0.9210 - val_loss: 1.6579 - val_accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2535 - accuracy: 0.9192 - val_loss: 2.2932 - val_accuracy: 0.7519\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2775 - accuracy: 0.9208 - val_loss: 1.5166 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2342 - accuracy: 0.9240 - val_loss: 1.3302 - val_accuracy: 0.8504\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.1701 - accuracy: 0.9406 - val_loss: 1.4357 - val_accuracy: 0.8452\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2285 - accuracy: 0.9276 - val_loss: 1.4428 - val_accuracy: 0.8259\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2008 - accuracy: 0.9322 - val_loss: 1.3468 - val_accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.1392 - accuracy: 0.9502 - val_loss: 1.3316 - val_accuracy: 0.8504\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.1455 - accuracy: 0.9473 - val_loss: 1.6099 - val_accuracy: 0.8296\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.1789 - accuracy: 0.9437 - val_loss: 1.6738 - val_accuracy: 0.8244\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2622 - accuracy: 0.9192 - val_loss: 1.3976 - val_accuracy: 0.8578\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2164 - accuracy: 0.9333 - val_loss: 1.4060 - val_accuracy: 0.8593\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.1066 - accuracy: 0.9638 - val_loss: 1.3303 - val_accuracy: 0.8689\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0829 - accuracy: 0.9730 - val_loss: 1.4443 - val_accuracy: 0.8622\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0950 - accuracy: 0.9690 - val_loss: 1.6447 - val_accuracy: 0.8363\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0961 - accuracy: 0.9657 - val_loss: 1.5230 - val_accuracy: 0.8548\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.2732 - accuracy: 0.9279 - val_loss: 1.5770 - val_accuracy: 0.8400\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 8s 40ms/step - loss: 0.2247 - accuracy: 0.9313 - val_loss: 1.4827 - val_accuracy: 0.8548\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0986 - accuracy: 0.9668 - val_loss: 1.3766 - val_accuracy: 0.8674\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 1.4124 - val_accuracy: 0.8704\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0714 - accuracy: 0.9762 - val_loss: 1.4288 - val_accuracy: 0.8763\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 1.5114 - val_accuracy: 0.8681\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1223 - accuracy: 0.9621 - val_loss: 1.5628 - val_accuracy: 0.8481\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.3473 - accuracy: 0.9133 - val_loss: 1.3321 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1136 - accuracy: 0.9629 - val_loss: 1.2441 - val_accuracy: 0.8726\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 8s 42ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 1.3095 - val_accuracy: 0.8681\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0782 - accuracy: 0.9784 - val_loss: 1.4648 - val_accuracy: 0.8615\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1581 - accuracy: 0.9519 - val_loss: 1.3102 - val_accuracy: 0.8711\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0632 - accuracy: 0.9798 - val_loss: 1.3859 - val_accuracy: 0.8733\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 1.5314 - val_accuracy: 0.8719\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0681 - accuracy: 0.9781 - val_loss: 1.4924 - val_accuracy: 0.8659\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0457 - accuracy: 0.9873 - val_loss: 1.5256 - val_accuracy: 0.8719\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1083 - accuracy: 0.9733 - val_loss: 1.8310 - val_accuracy: 0.8289\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.2320 - accuracy: 0.9305 - val_loss: 1.5457 - val_accuracy: 0.8593\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0970 - accuracy: 0.9695 - val_loss: 1.5985 - val_accuracy: 0.8652\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0764 - accuracy: 0.9733 - val_loss: 1.5738 - val_accuracy: 0.8704\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0771 - accuracy: 0.9779 - val_loss: 1.5910 - val_accuracy: 0.8696\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 8s 42ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 1.5256 - val_accuracy: 0.8778\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 8s 41ms/step - loss: 0.0352 - accuracy: 0.9922 - val_loss: 1.5972 - val_accuracy: 0.8726\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 1.7875 - val_accuracy: 0.8504\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 1.7390 - val_accuracy: 0.8681\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 8s 42ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 1.7693 - val_accuracy: 0.8563\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1942 - accuracy: 0.9462 - val_loss: 1.5873 - val_accuracy: 0.8393\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1336 - accuracy: 0.9590 - val_loss: 1.4508 - val_accuracy: 0.8622\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0699 - accuracy: 0.9783 - val_loss: 1.4492 - val_accuracy: 0.8778\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 1.6938 - val_accuracy: 0.8607\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0479 - accuracy: 0.9862 - val_loss: 1.5207 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0296 - accuracy: 0.9932 - val_loss: 1.6817 - val_accuracy: 0.8763\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0794 - accuracy: 0.9757 - val_loss: 1.5821 - val_accuracy: 0.8733\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0895 - accuracy: 0.9717 - val_loss: 1.6645 - val_accuracy: 0.8733\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 1.6317 - val_accuracy: 0.8741\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0269 - accuracy: 0.9938 - val_loss: 1.7622 - val_accuracy: 0.8748\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0233 - accuracy: 0.9952 - val_loss: 1.8367 - val_accuracy: 0.8726\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0197 - accuracy: 0.9960 - val_loss: 1.8683 - val_accuracy: 0.8681\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0191 - accuracy: 0.9965 - val_loss: 2.0281 - val_accuracy: 0.8659\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1573 - accuracy: 0.9627 - val_loss: 1.8699 - val_accuracy: 0.8244\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1552 - accuracy: 0.9554 - val_loss: 1.6527 - val_accuracy: 0.8659\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0691 - accuracy: 0.9806 - val_loss: 1.6580 - val_accuracy: 0.8719\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 1.5936 - val_accuracy: 0.8778\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 1.7334 - val_accuracy: 0.8763\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 1.8399 - val_accuracy: 0.8726\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0897 - accuracy: 0.9740 - val_loss: 1.8335 - val_accuracy: 0.8526\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0401 - accuracy: 0.9906 - val_loss: 1.6922 - val_accuracy: 0.8719\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 1.8762 - val_accuracy: 0.8815\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.0304 - accuracy: 0.9916 - val_loss: 1.9270 - val_accuracy: 0.8748\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1516 - accuracy: 0.9589 - val_loss: 1.7154 - val_accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 8s 43ms/step - loss: 0.1695 - accuracy: 0.9590 - val_loss: 1.4946 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 8s 41ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 1.6767 - val_accuracy: 0.8741\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0767 - accuracy: 0.9768 - val_loss: 1.6123 - val_accuracy: 0.8711\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0243 - accuracy: 0.9957 - val_loss: 1.7871 - val_accuracy: 0.8741\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 8s 39ms/step - loss: 0.0176 - accuracy: 0.9970 - val_loss: 1.8349 - val_accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(16000,1)))\n",
    "model.add(layers.Conv1D(32,9))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv1D(64,7))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Conv1D(256,5))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.AveragePooling1D(pool_size=40))\n",
    "model.add(layers.MaxPooling1D(pool_size=9))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 19ms/step - loss: 0.4374 - accuracy: 0.8622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43744343519210815, 0.8622221946716309]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41e74be16d15307d9f039f42bdba433d4433ec6233894682bf41214f89ea7b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
