{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Veysi ADIN 19 SEPT 2022\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# Using GPU\n",
    "import os\n",
    "import scipy.io as scpy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV data, that is already converted from wav files in speech command dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258107/1926382603.py:13: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n",
      "/tmp/ipykernel_258107/1926382603.py:35: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n",
      "/tmp/ipykernel_258107/1926382603.py:56: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  filename_csv_no = filename_csv_no.astype(np.str)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, os.path\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "num_of_samples = 3000\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_no_csv'\n",
    "filename_csv_no = np.zeros(num_of_samples)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_no = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_no_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_no[i][j] = rows[j][1]\n",
    "\n",
    "\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_yes_csv'\n",
    "filename_csv_no = np.zeros(num_of_samples)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_yes = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_yes_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_yes[i][j] = rows[j][1]\n",
    "\n",
    "path = '/home/veysiadn/Downloads/google_speech_3classes/speech_zero_csv'\n",
    "filename_csv_no = np.zeros(3000)\n",
    "filename_csv_no = filename_csv_no.astype(np.str)\n",
    "i=0;\n",
    "for file_name in os.listdir(path):\n",
    "    filename_csv_no[i] = file_name;\n",
    "    i= i+1;\n",
    "    \n",
    "samples_zero = np.zeros((num_of_samples,16000))\n",
    "for i in range(num_of_samples):\n",
    "    file = open(str('/home/veysiadn/Downloads/google_speech_3classes/speech_zero_csv/' + filename_csv_no[i]))\n",
    "    type(file)\n",
    "    csvreader = csv.reader(file)\n",
    "    header = []\n",
    "    header = next(csvreader)\n",
    "    rows = []\n",
    "    for row in csvreader:\n",
    "            rows.append(row)\n",
    "    for j in range(len(rows)):\n",
    "        samples_zero[i][j] = rows[j][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shapes and prepare data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 16000)\n",
      "(3000, 16000)\n",
      "(3000, 16000)\n",
      "(9000, 16000)\n",
      "(9000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(samples_no.shape)\n",
    "print(samples_yes.shape)\n",
    "print(samples_zero.shape)\n",
    "num_of_classes = 3 \n",
    "y_data = np.zeros((num_of_samples* num_of_classes,1))\n",
    "y_data[num_of_samples:2*num_of_samples] = 1\n",
    "y_data[2*num_of_samples:3*num_of_samples] = 2\n",
    "x_data = np.concatenate((samples_no,samples_yes,samples_zero),axis=0)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# split into train test sets\n",
    "x_train, x_val_to_use, y_train, y_val_to_use = train_test_split(x_data, y_data, test_size=0.3, random_state=SEED)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_to_use, y_val_to_use, test_size=0.5, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 1350, 1350)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "dense_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(16000,)),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "dense_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-2),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "dense_model.summary()              \n",
    "\n",
    "history=dense_model.fit(x_train,y_train, validation_data=(x_val,y_val), epochs=100,verbose=1)\n",
    "# dense_model.evaluate(val_dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('dense_model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating dense_model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_model_paper\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_27 (Conv1D)          (None, 15985, 8)          136       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 15985, 8)          0         \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 1998, 8)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 1983, 8)           1032      \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 1983, 8)           0         \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 495, 8)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 123, 8)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 984)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 3)                 2955      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,123\n",
      "Trainable params: 4,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 631.2736 - accuracy: 0.3916 - val_loss: 449.2159 - val_accuracy: 0.4104\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 340.7331 - accuracy: 0.4294 - val_loss: 288.9962 - val_accuracy: 0.4548\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 240.2242 - accuracy: 0.4741 - val_loss: 221.6218 - val_accuracy: 0.4859\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 183.7414 - accuracy: 0.5122 - val_loss: 187.9987 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 149.0003 - accuracy: 0.5430 - val_loss: 151.8530 - val_accuracy: 0.5400\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 124.1489 - accuracy: 0.5694 - val_loss: 132.3595 - val_accuracy: 0.5541\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 104.8724 - accuracy: 0.5884 - val_loss: 117.2729 - val_accuracy: 0.5615\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 89.4685 - accuracy: 0.6038 - val_loss: 105.4506 - val_accuracy: 0.5822\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 77.2538 - accuracy: 0.6186 - val_loss: 93.3419 - val_accuracy: 0.5815\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 66.6429 - accuracy: 0.6306 - val_loss: 78.0038 - val_accuracy: 0.6022\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 57.1462 - accuracy: 0.6384 - val_loss: 65.4118 - val_accuracy: 0.6074\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 48.1664 - accuracy: 0.6386 - val_loss: 54.5012 - val_accuracy: 0.6133\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 38.8311 - accuracy: 0.6384 - val_loss: 39.3209 - val_accuracy: 0.6200\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 27.1381 - accuracy: 0.6376 - val_loss: 24.2713 - val_accuracy: 0.6052\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 18.0018 - accuracy: 0.6116 - val_loss: 16.7855 - val_accuracy: 0.5815\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 12.7342 - accuracy: 0.5759 - val_loss: 11.6973 - val_accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 8.9260 - accuracy: 0.5343 - val_loss: 8.4511 - val_accuracy: 0.4963\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 6.5271 - accuracy: 0.4873 - val_loss: 6.1161 - val_accuracy: 0.4489\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 4.6298 - accuracy: 0.4414 - val_loss: 4.0693 - val_accuracy: 0.4356\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 3.1879 - accuracy: 0.4005 - val_loss: 3.0189 - val_accuracy: 0.3859\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.5000 - accuracy: 0.3687 - val_loss: 2.5352 - val_accuracy: 0.3704\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 2.0930 - accuracy: 0.3546 - val_loss: 2.2205 - val_accuracy: 0.3511\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.8482 - accuracy: 0.3478 - val_loss: 1.9825 - val_accuracy: 0.3415\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.6958 - accuracy: 0.3441 - val_loss: 1.8086 - val_accuracy: 0.3452\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.6097 - accuracy: 0.3421 - val_loss: 1.7032 - val_accuracy: 0.3452\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.5469 - accuracy: 0.3389 - val_loss: 1.6247 - val_accuracy: 0.3400\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4990 - accuracy: 0.3371 - val_loss: 1.5728 - val_accuracy: 0.3452\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4617 - accuracy: 0.3368 - val_loss: 1.5249 - val_accuracy: 0.3459\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.4276 - accuracy: 0.3354 - val_loss: 1.4815 - val_accuracy: 0.3474\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3944 - accuracy: 0.3348 - val_loss: 1.4442 - val_accuracy: 0.3459\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3671 - accuracy: 0.3348 - val_loss: 1.4113 - val_accuracy: 0.3422\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3425 - accuracy: 0.3360 - val_loss: 1.3846 - val_accuracy: 0.3459\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.3193 - accuracy: 0.3340 - val_loss: 1.3566 - val_accuracy: 0.3467\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2967 - accuracy: 0.3333 - val_loss: 1.3286 - val_accuracy: 0.3437\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2781 - accuracy: 0.3317 - val_loss: 1.3066 - val_accuracy: 0.3459\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2577 - accuracy: 0.3327 - val_loss: 1.2833 - val_accuracy: 0.3437\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2410 - accuracy: 0.3338 - val_loss: 1.2600 - val_accuracy: 0.3407\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2225 - accuracy: 0.3356 - val_loss: 1.2429 - val_accuracy: 0.3437\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.2069 - accuracy: 0.3356 - val_loss: 1.2336 - val_accuracy: 0.3474\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1930 - accuracy: 0.3349 - val_loss: 1.2243 - val_accuracy: 0.3430\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1811 - accuracy: 0.3333 - val_loss: 1.2140 - val_accuracy: 0.3407\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1696 - accuracy: 0.3335 - val_loss: 1.2042 - val_accuracy: 0.3407\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1586 - accuracy: 0.3333 - val_loss: 1.1976 - val_accuracy: 0.3400\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.3340 - val_loss: 1.1868 - val_accuracy: 0.3363\n",
      "Epoch 45/100\n",
      "138/197 [====================>.........] - ETA: 0s - loss: 1.1349 - accuracy: 0.3408"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/veysiadn/model-training/acustic-emission-models/test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train ,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)   \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Plotting accuracy and loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/test.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "model = tf.keras.Sequential(name='conv_model_paper')\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(16000,1)))\n",
    "model.add(tf.keras.layers.Conv1D(8,7))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=8))\n",
    "model.add(tf.keras.layers.Conv1D(8,5))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train ,epochs=100, validation_data=(x_val, y_val), verbose=1)   \n",
    "\n",
    "\n",
    "# Plotting accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('Model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2877693772315979, 0.9140740633010864]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 15992, 32)         320       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 15992, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 15992, 32)         0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 15992, 32)         0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 15986, 64)         14400     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 15986, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 15986, 64)         0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 15986, 64)         0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 15982, 256)        82176     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 15982, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 15982, 256)        0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 15982, 256)        0         \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 399, 256)         0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 44, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 11264)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 33795     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,099\n",
      "Trainable params: 131,395\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "197/197 [==============================] - 18s 88ms/step - loss: 0.9167 - accuracy: 0.5716 - val_loss: 0.8671 - val_accuracy: 0.5867\n",
      "Epoch 2/10\n",
      "197/197 [==============================] - 17s 88ms/step - loss: 0.6827 - accuracy: 0.7275 - val_loss: 0.7096 - val_accuracy: 0.7215\n",
      "Epoch 3/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.5688 - accuracy: 0.7827 - val_loss: 0.5908 - val_accuracy: 0.7933\n",
      "Epoch 4/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.5224 - accuracy: 0.8113 - val_loss: 0.5945 - val_accuracy: 0.7985\n",
      "Epoch 5/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.5016 - accuracy: 0.8121 - val_loss: 0.5245 - val_accuracy: 0.8267\n",
      "Epoch 6/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.4558 - accuracy: 0.8351 - val_loss: 0.5064 - val_accuracy: 0.8348\n",
      "Epoch 7/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.4464 - accuracy: 0.8456 - val_loss: 0.4714 - val_accuracy: 0.8593\n",
      "Epoch 8/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.4352 - accuracy: 0.8459 - val_loss: 0.5320 - val_accuracy: 0.8193\n",
      "Epoch 9/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.4328 - accuracy: 0.8481 - val_loss: 0.5423 - val_accuracy: 0.7948\n",
      "Epoch 10/10\n",
      "197/197 [==============================] - 17s 87ms/step - loss: 0.4133 - accuracy: 0.8546 - val_loss: 0.4611 - val_accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(16000,1)))\n",
    "model.add(layers.Conv1D(32,9))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Conv1D(64,7))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Conv1D(256,5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.AveragePooling1D(pool_size=40))\n",
    "model.add(layers.MaxPooling1D(pool_size=9))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 19ms/step - loss: 0.4374 - accuracy: 0.8622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43744343519210815, 0.8622221946716309]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41e74be16d15307d9f039f42bdba433d4433ec6233894682bf41214f89ea7b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
