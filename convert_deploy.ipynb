{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and USE GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# Using GPU\n",
    "import os\n",
    "import scipy.io as scpy\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1000)\n",
      "(15000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load .mat data, will be loaded as dictionary object so you need to extract values from it.\n",
    "data = scpy.loadmat(\"matlab15000.mat\")\n",
    "# Extracting x_train from the mat file dictionary.\n",
    "x_data = data[\"XTrain\"]\n",
    "# Extracting y_train from the mat file dictionary.\n",
    "y_data = data[\"unnamed\"]\n",
    "# Converting x_train and y_train to a numpy array.\n",
    "x_data = np.array(x_data,dtype='float32')\n",
    "y_train = np.array(y_data,dtype='float32')\n",
    "# Verifying the shapes.\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# split into train test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=SEED)\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_test[:1500]\n",
    "y_val = y_test[:1500]\n",
    "x_test_to_use = x_test[1500:]\n",
    "y_test_to_use = y_test[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dimension of train, test and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1500, 1500)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_val), len(x_test_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Convolutional Model as Described in the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_model_paper\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 994, 32)           256       \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 994, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 994, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 124, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 120, 48)           7728      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 120, 48)          192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 120, 48)           0         \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 30, 48)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 7, 48)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 7, 48)             0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 336)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 32)                10784     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,243\n",
      "Trainable params: 20,083\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veysiadn/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0789 - accuracy: 0.6097 - val_loss: 0.5444 - val_accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6366 - accuracy: 0.7433 - val_loss: 0.3893 - val_accuracy: 0.8467\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7948 - val_loss: 0.3290 - val_accuracy: 0.8773\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8249 - val_loss: 0.2942 - val_accuracy: 0.9007\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8472 - val_loss: 0.2731 - val_accuracy: 0.9107\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8598 - val_loss: 0.2504 - val_accuracy: 0.9180\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8716 - val_loss: 0.2296 - val_accuracy: 0.9220\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8800 - val_loss: 0.2268 - val_accuracy: 0.9207\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8891 - val_loss: 0.2117 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.8935 - val_loss: 0.1913 - val_accuracy: 0.9393\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8976 - val_loss: 0.1806 - val_accuracy: 0.9427\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9031 - val_loss: 0.1737 - val_accuracy: 0.9440\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9049 - val_loss: 0.1711 - val_accuracy: 0.9367\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9105 - val_loss: 0.1574 - val_accuracy: 0.9407\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9138 - val_loss: 0.1626 - val_accuracy: 0.9453\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.9134 - val_loss: 0.1507 - val_accuracy: 0.9467\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9133 - val_loss: 0.1456 - val_accuracy: 0.9467\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9205 - val_loss: 0.1304 - val_accuracy: 0.9513\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2131 - accuracy: 0.9206 - val_loss: 0.1301 - val_accuracy: 0.9513\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.9216 - val_loss: 0.1204 - val_accuracy: 0.9580\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9256 - val_loss: 0.1177 - val_accuracy: 0.9593\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2032 - accuracy: 0.9234 - val_loss: 0.1119 - val_accuracy: 0.9593\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2013 - accuracy: 0.9286 - val_loss: 0.1123 - val_accuracy: 0.9547\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9309 - val_loss: 0.1034 - val_accuracy: 0.9613\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9295 - val_loss: 0.1029 - val_accuracy: 0.9580\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9335 - val_loss: 0.1041 - val_accuracy: 0.9627\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9333 - val_loss: 0.0976 - val_accuracy: 0.9633\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.9366 - val_loss: 0.0936 - val_accuracy: 0.9673\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9363 - val_loss: 0.0931 - val_accuracy: 0.9693\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1720 - accuracy: 0.9367 - val_loss: 0.0874 - val_accuracy: 0.9640\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.9363 - val_loss: 0.0914 - val_accuracy: 0.9660\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9396 - val_loss: 0.0871 - val_accuracy: 0.9680\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1629 - accuracy: 0.9416 - val_loss: 0.0799 - val_accuracy: 0.9700\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1621 - accuracy: 0.9431 - val_loss: 0.0838 - val_accuracy: 0.9680\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.9461 - val_loss: 0.0820 - val_accuracy: 0.9687\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1567 - accuracy: 0.9427 - val_loss: 0.0778 - val_accuracy: 0.9700\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9442 - val_loss: 0.0749 - val_accuracy: 0.9673\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9452 - val_loss: 0.0746 - val_accuracy: 0.9700\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1493 - accuracy: 0.9458 - val_loss: 0.0745 - val_accuracy: 0.9693\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1484 - accuracy: 0.9432 - val_loss: 0.0668 - val_accuracy: 0.9733\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1446 - accuracy: 0.9465 - val_loss: 0.0709 - val_accuracy: 0.9727\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9513 - val_loss: 0.0682 - val_accuracy: 0.9713\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1444 - accuracy: 0.9473 - val_loss: 0.0648 - val_accuracy: 0.9720\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9498 - val_loss: 0.0654 - val_accuracy: 0.9733\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9496 - val_loss: 0.0588 - val_accuracy: 0.9753\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9507 - val_loss: 0.0636 - val_accuracy: 0.9727\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9488 - val_loss: 0.0607 - val_accuracy: 0.9780\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9523 - val_loss: 0.0618 - val_accuracy: 0.9747\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1223 - accuracy: 0.9532 - val_loss: 0.0552 - val_accuracy: 0.9780\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9543 - val_loss: 0.0605 - val_accuracy: 0.9753\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1259 - accuracy: 0.9545 - val_loss: 0.0526 - val_accuracy: 0.9793\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.9563 - val_loss: 0.0504 - val_accuracy: 0.9773\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9549 - val_loss: 0.0555 - val_accuracy: 0.9793\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9568 - val_loss: 0.0549 - val_accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1124 - accuracy: 0.9596 - val_loss: 0.0506 - val_accuracy: 0.9793\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9576 - val_loss: 0.0460 - val_accuracy: 0.9813\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1184 - accuracy: 0.9567 - val_loss: 0.0456 - val_accuracy: 0.9833\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9576 - val_loss: 0.0477 - val_accuracy: 0.9847\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.9605 - val_loss: 0.0636 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1078 - accuracy: 0.9612 - val_loss: 0.0430 - val_accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9596 - val_loss: 0.0418 - val_accuracy: 0.9847\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9622 - val_loss: 0.0443 - val_accuracy: 0.9847\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1057 - accuracy: 0.9635 - val_loss: 0.0425 - val_accuracy: 0.9840\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.9631 - val_loss: 0.0412 - val_accuracy: 0.9853\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9631 - val_loss: 0.0481 - val_accuracy: 0.9853\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9638 - val_loss: 0.0392 - val_accuracy: 0.9880\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1041 - accuracy: 0.9612 - val_loss: 0.0449 - val_accuracy: 0.9853\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9649 - val_loss: 0.0398 - val_accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9655 - val_loss: 0.0381 - val_accuracy: 0.9860\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.9632 - val_loss: 0.0398 - val_accuracy: 0.9867\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9658 - val_loss: 0.0377 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9657 - val_loss: 0.0383 - val_accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9665 - val_loss: 0.0408 - val_accuracy: 0.9860\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9679 - val_loss: 0.0357 - val_accuracy: 0.9873\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9676 - val_loss: 0.0357 - val_accuracy: 0.9887\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9673 - val_loss: 0.0342 - val_accuracy: 0.9880\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9684 - val_loss: 0.0391 - val_accuracy: 0.9847\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0869 - accuracy: 0.9668 - val_loss: 0.0318 - val_accuracy: 0.9900\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9677 - val_loss: 0.0364 - val_accuracy: 0.9880\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0836 - accuracy: 0.9701 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0826 - accuracy: 0.9709 - val_loss: 0.0310 - val_accuracy: 0.9887\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9701 - val_loss: 0.0304 - val_accuracy: 0.9887\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0812 - accuracy: 0.9706 - val_loss: 0.0310 - val_accuracy: 0.9900\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0845 - accuracy: 0.9714 - val_loss: 0.0293 - val_accuracy: 0.9880\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.0307 - val_accuracy: 0.9873\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0799 - accuracy: 0.9718 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0764 - accuracy: 0.9733 - val_loss: 0.0345 - val_accuracy: 0.9913\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0768 - accuracy: 0.9718 - val_loss: 0.0279 - val_accuracy: 0.9893\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0770 - accuracy: 0.9719 - val_loss: 0.0269 - val_accuracy: 0.9900\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.0265 - val_accuracy: 0.9913\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.9728 - val_loss: 0.0291 - val_accuracy: 0.9887\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0747 - accuracy: 0.9734 - val_loss: 0.0230 - val_accuracy: 0.9947\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 0.0244 - val_accuracy: 0.9927\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0771 - accuracy: 0.9736 - val_loss: 0.0247 - val_accuracy: 0.9933\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0733 - accuracy: 0.9732 - val_loss: 0.0248 - val_accuracy: 0.9913\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0716 - accuracy: 0.9752 - val_loss: 0.0243 - val_accuracy: 0.9920\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0678 - accuracy: 0.9746 - val_loss: 0.0246 - val_accuracy: 0.9927\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0690 - accuracy: 0.9745 - val_loss: 0.0256 - val_accuracy: 0.9907\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0705 - accuracy: 0.9757 - val_loss: 0.0237 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0676 - accuracy: 0.9763 - val_loss: 0.0247 - val_accuracy: 0.9933\n",
      "Training results\n",
      "Training Accuracy: 0.9763333201408386\n",
      "Training Loss: 0.06763042509555817\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.9933333396911621\n",
      "Validation Loss: 0.024722926318645477\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "model = tf.keras.Sequential(name='conv_model_paper')\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(1000,1)))\n",
    "model.add(tf.keras.layers.Conv1D(32,7))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=8))\n",
    "model.add(tf.keras.layers.Conv1D(48,5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train ,epochs=100, validation_data=(x_val, y_val), verbose=1)   \n",
    "\n",
    "\n",
    "# Plotting accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('Model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model without optimization and convert it to tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "2022-10-05 14:31:26.555448: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:31:26.555466: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:31:26.555553: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: models/\n",
      "2022-10-05 14:31:26.557255: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:31:26.557267: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: models/\n",
      "2022-10-05 14:31:26.562441: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:31:26.607030: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: models/\n",
      "2022-10-05 14:31:26.618083: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 62528 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88312"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL = 'models/'\n",
    "tf.saved_model.save(model, SAVED_MODEL)\n",
    "float_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "float_tflite_model = float_converter.convert()\n",
    "import pathlib\n",
    "tflite_model_file = pathlib.Path('conv_model_paper.tflite')\n",
    "tflite_model_file.write_bytes(float_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize same model and save it in tflite format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Layer conv1d_8:<class 'keras.layers.convolutional.conv1d.Conv1D'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/veysiadn/model-training/acustic-emission-models/convert_deploy.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/convert_deploy.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m quantized_model \u001b[39m=\u001b[39m tfmot\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mquantize_model(model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/convert_deploy.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m SAVED_MODEL \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/veysiadn/model-training/acustic-emission-models/convert_deploy.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msave(model, SAVED_MODEL)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:141\u001b[0m, in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    137\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m`to_quantize` can only either be a tf.keras Sequential or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mFunctional model.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m annotated_model \u001b[39m=\u001b[39m quantize_annotate_model(to_quantize)\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m quantize_apply(annotated_model)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbool_gauge\u001b[39m.\u001b[39mget_cell(MonitorBoolGauge\u001b[39m.\u001b[39m_FAILURE_LABEL)\u001b[39m.\u001b[39mset(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[39mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbool_gauge\u001b[39m.\u001b[39mget_cell(MonitorBoolGauge\u001b[39m.\u001b[39m_SUCCESS_LABEL)\u001b[39m.\u001b[39mset(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:479\u001b[0m, in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme)\u001b[0m\n\u001b[1;32m    473\u001b[0m quantize_registry \u001b[39m=\u001b[39m scheme\u001b[39m.\u001b[39mget_quantize_registry()\n\u001b[1;32m    475\u001b[0m \u001b[39m# 4. Actually quantize all the relevant layers in the model. This is done by\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39m# wrapping the layers with QuantizeWrapper, and passing the associated\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m# `QuantizeConfig`.\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m \u001b[39mreturn\u001b[39;00m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mclone_model(\n\u001b[1;32m    480\u001b[0m     transformed_model, input_tensors\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, clone_function\u001b[39m=\u001b[39;49m_quantize)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/models/cloning.py:501\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    498\u001b[0m     clone_function \u001b[39m=\u001b[39m _clone_layer\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, Sequential):\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mreturn\u001b[39;00m _clone_sequential_model(\n\u001b[1;32m    502\u001b[0m         model, input_tensors\u001b[39m=\u001b[39;49minput_tensors, layer_fn\u001b[39m=\u001b[39;49mclone_function\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m _clone_functional_model(\n\u001b[1;32m    506\u001b[0m         model, input_tensors\u001b[39m=\u001b[39minput_tensors, layer_fn\u001b[39m=\u001b[39mclone_function\n\u001b[1;32m    507\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/models/cloning.py:362\u001b[0m, in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, InputLayer) \u001b[39mand\u001b[39;00m input_tensors \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39m# If input tensors are provided, the original model's InputLayer is\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39m# overwritten with a different InputLayer.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    359\u001b[0m cloned_layer \u001b[39m=\u001b[39m (\n\u001b[1;32m    360\u001b[0m     _clone_layer(layer)\n\u001b[1;32m    361\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, InputLayer)\n\u001b[0;32m--> 362\u001b[0m     \u001b[39melse\u001b[39;00m layer_fn(layer)\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m layers\u001b[39m.\u001b[39mappend(cloned_layer)\n\u001b[1;32m    365\u001b[0m layer_map[layer] \u001b[39m=\u001b[39m cloned_layer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py:429\u001b[0m, in \u001b[0;36mquantize_apply.<locals>._quantize\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quantize_config:\n\u001b[1;32m    424\u001b[0m   error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    425\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not supported. You can quantize this \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    426\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mlayer by passing a `tfmot.quantization.keras.QuantizeConfig` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    427\u001b[0m       \u001b[39m'\u001b[39m\u001b[39minstance to the `quantize_annotate_layer` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    428\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mAPI.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    430\u001b[0m       error_msg\u001b[39m.\u001b[39mformat(layer\u001b[39m.\u001b[39mname, layer\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m,\n\u001b[1;32m    431\u001b[0m                        quantize_registry\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m))\n\u001b[1;32m    433\u001b[0m \u001b[39m# `QuantizeWrapper` does not copy any additional layer params from\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# `QuantizeAnnotate`. This should generally be fine, but occasionally\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# `QuantizeAnnotate` wrapper may contain `batch_input_shape` like params.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# TODO(pulkitb): Ensure this does not affect model cloning.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mreturn\u001b[39;00m quantize_wrapper\u001b[39m.\u001b[39mQuantizeWrapperV2(\n\u001b[1;32m    438\u001b[0m     layer, quantize_config)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Layer conv1d_8:<class 'keras.layers.convolutional.conv1d.Conv1D'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API."
     ]
    }
   ],
   "source": [
    "quantized_model = tfmot.quantization.keras.quantize_model(model)\n",
    "SAVED_MODEL = 'models/'\n",
    "tf.saved_model.save(model, SAVED_MODEL)\n",
    "float_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "float_tflite_model = float_converter.convert()\n",
    "import pathlib\n",
    "tflite_model_file = pathlib.Path('conv_model_paper_quantized.tflite')\n",
    "tflite_model_file.write_bytes(float_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the model described in the paper to make it suitable for conversion to TFLite, and quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_modified_conv_model_paper_paper_2D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Reshape (Reshape)           (None, 1000, 1, 1)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1000, 1, 32)       1600      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 125, 1, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 125, 1, 48)        38448     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 1, 48)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 1, 48)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                12320     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,523\n",
      "Trainable params: 53,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "  1/375 [..............................] - ETA: 1:04 - loss: 1.0684 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veysiadn/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 2s 4ms/step - loss: 0.7855 - accuracy: 0.6507 - val_loss: 0.5458 - val_accuracy: 0.7800\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.8374 - val_loss: 0.3858 - val_accuracy: 0.8520\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8956 - val_loss: 0.3229 - val_accuracy: 0.8893\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9178 - val_loss: 0.2566 - val_accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2326 - accuracy: 0.9310 - val_loss: 0.2132 - val_accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2019 - accuracy: 0.9397 - val_loss: 0.1852 - val_accuracy: 0.9427\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9438 - val_loss: 0.1601 - val_accuracy: 0.9467\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9507 - val_loss: 0.1473 - val_accuracy: 0.9540\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9551 - val_loss: 0.1376 - val_accuracy: 0.9520\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1281 - accuracy: 0.9613 - val_loss: 0.1101 - val_accuracy: 0.9640\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1172 - accuracy: 0.9628 - val_loss: 0.1048 - val_accuracy: 0.9667\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1047 - accuracy: 0.9696 - val_loss: 0.0882 - val_accuracy: 0.9727\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0950 - accuracy: 0.9723 - val_loss: 0.0868 - val_accuracy: 0.9767\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9763 - val_loss: 0.0756 - val_accuracy: 0.9780\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.0646 - val_accuracy: 0.9820\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.0592 - val_accuracy: 0.9833\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9807 - val_loss: 0.0534 - val_accuracy: 0.9860\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.9820 - val_loss: 0.0540 - val_accuracy: 0.9867\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9832 - val_loss: 0.0544 - val_accuracy: 0.9853\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.0490 - val_accuracy: 0.9847\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9852 - val_loss: 0.0449 - val_accuracy: 0.9853\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.9866 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.0427 - val_accuracy: 0.9880\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0410 - val_accuracy: 0.9880\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.0391 - val_accuracy: 0.9873\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.0414 - val_accuracy: 0.9873\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0508 - val_accuracy: 0.9820\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0381 - val_accuracy: 0.9873\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.0326 - val_accuracy: 0.9920\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0247 - accuracy: 0.9935 - val_loss: 0.0347 - val_accuracy: 0.9887\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.0356 - val_accuracy: 0.9880\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0298 - val_accuracy: 0.9933\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.0416 - val_accuracy: 0.9900\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9948 - val_loss: 0.0288 - val_accuracy: 0.9947\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0311 - val_accuracy: 0.9927\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0315 - val_accuracy: 0.9927\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0310 - val_accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0258 - val_accuracy: 0.9940\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.0291 - val_accuracy: 0.9933\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 0.0410 - val_accuracy: 0.9880\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0288 - val_accuracy: 0.9940\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0247 - val_accuracy: 0.9933\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0273 - val_accuracy: 0.9927\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0239 - val_accuracy: 0.9940\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0256 - val_accuracy: 0.9933\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0230 - val_accuracy: 0.9940\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0277 - val_accuracy: 0.9933\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0604 - val_accuracy: 0.9833\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0254 - val_accuracy: 0.9947\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0354 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0337 - val_accuracy: 0.9893\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0260 - val_accuracy: 0.9953\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0285 - val_accuracy: 0.9947\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0284 - val_accuracy: 0.9940\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0261 - val_accuracy: 0.9947\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0217 - val_accuracy: 0.9973\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0218 - val_accuracy: 0.9953\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0267 - val_accuracy: 0.9967\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0211 - val_accuracy: 0.9953\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0285 - val_accuracy: 0.9953\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0305 - val_accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0242 - val_accuracy: 0.9960\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9960\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0246 - val_accuracy: 0.9953\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9953\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9920\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 9.8077e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9953\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0318 - val_accuracy: 0.9920\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0237 - val_accuracy: 0.9967\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1019 - val_accuracy: 0.9727\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0217 - val_accuracy: 0.9960\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.5439e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9960\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 5.9093e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9960\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.5290e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9960\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.9330e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9960\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 4.0795e-04 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9973\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.8535e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9960\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0362 - val_accuracy: 0.9927\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0277 - val_accuracy: 0.9933\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.0847e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9953\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.3758e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9960\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8406e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9953\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.6579e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9960\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.5602e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9960\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5989e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9940\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1849e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9953\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8683e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9953\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4271e-04 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9887\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0281 - val_accuracy: 0.9933\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 8.5790e-04 - accuracy: 0.9998 - val_loss: 0.0368 - val_accuracy: 0.9920\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.5603e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9940\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3096e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9898e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8641e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9953\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6667e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9960\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6085e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9960\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4795e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9960\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3646e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9960\n",
      "Training results\n",
      "Training Accuracy: 1.0\n",
      "Training Loss: 0.00013645575381815434\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.9959999918937683\n",
      "Validation Loss: 0.02530823089182377\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from genericpath import samefile\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "modified_conv_model_paper = tf.keras.Sequential(name='conv_modified_conv_model_paper_paper_2D')\n",
    "modified_conv_model_paper.add(tf.keras.layers.Reshape((1000,1,1),name='Reshape', input_shape=(1000,)))\n",
    "modified_conv_model_paper.add(tf.keras.layers.Conv2D(32,7,padding='same',activation='relu'))\n",
    "modified_conv_model_paper.add(tf.keras.layers.MaxPooling2D(8,8,padding='same'))\n",
    "modified_conv_model_paper.add(tf.keras.layers.Conv2D(48,5,padding='same',activation='relu'))\n",
    "modified_conv_model_paper.add(tf.keras.layers.MaxPooling2D(4,4,padding='same'))\n",
    "modified_conv_model_paper.add(tf.keras.layers.MaxPooling2D(4,4,padding='same'))\n",
    "modified_conv_model_paper.add(tf.keras.layers.Flatten())\n",
    "modified_conv_model_paper.add(tf.keras.layers.Dense(32))\n",
    "modified_conv_model_paper.add(tf.keras.layers.Dense(32))\n",
    "modified_conv_model_paper.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "print(modified_conv_model_paper.summary())\n",
    "modified_conv_model_paper.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = modified_conv_model_paper.fit(x_train, y_train ,epochs=100, validation_data=(x_val, y_val), verbose=1)   \n",
    "\n",
    "\n",
    "# Plotting accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('modified_conv_model_paper loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating modified_conv_model_paper\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model as .tflite and .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Reshape_input with unsupported characters which will be renamed to reshape_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/modified_conv_model_paper/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/modified_conv_model_paper/assets\n",
      "2022-10-05 14:36:37.560649: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:36:37.560665: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:36:37.560740: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: models/modified_conv_model_paper\n",
      "2022-10-05 14:36:37.561617: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:36:37.561630: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: models/modified_conv_model_paper\n",
      "2022-10-05 14:36:37.563944: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:36:37.592079: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: models/modified_conv_model_paper\n",
      "2022-10-05 14:36:37.598329: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 37588 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219992"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL = 'models/modified_conv_model_paper'\n",
    "tf.saved_model.save(modified_conv_model_paper, SAVED_MODEL)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "modidified_conv_model_converted = converter.convert()\n",
    "import pathlib\n",
    "tflite_model_file = pathlib.Path('conv_model_paper_2D.tflite')\n",
    "tflite_model_file.write_bytes(modidified_conv_model_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize same model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 14:45:00.926486: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:45:00.926504: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:45:00.926583: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: models/modified_conv_model_paper\n",
      "2022-10-05 14:45:00.927504: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:45:00.927516: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: models/modified_conv_model_paper\n",
      "2022-10-05 14:45:00.930105: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:45:00.959901: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: models/modified_conv_model_paper\n",
      "2022-10-05 14:45:00.966900: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 40315 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61280"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL = 'models/modified_conv_model_paper'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_file = pathlib.Path('conv_model_paper_2D_quantized.tflite')\n",
    "tflite_model_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experimantal random 2D convolutional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_2D_conv_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Reshape (Reshape)           (None, 1000, 1, 1)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1000, 1, 8)        208       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 500, 1, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 4000)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 12003     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,211\n",
      "Trainable params: 12,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "  1/375 [..............................] - ETA: 1:00 - loss: 1.0969 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veysiadn/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8108 - accuracy: 0.6982 - val_loss: 0.5651 - val_accuracy: 0.8360\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4313 - accuracy: 0.8749 - val_loss: 0.3283 - val_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9178 - val_loss: 0.2398 - val_accuracy: 0.9180\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2127 - accuracy: 0.9351 - val_loss: 0.1949 - val_accuracy: 0.9347\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.9479 - val_loss: 0.1678 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1500 - accuracy: 0.9541 - val_loss: 0.1441 - val_accuracy: 0.9533\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9597 - val_loss: 0.1308 - val_accuracy: 0.9600\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1149 - accuracy: 0.9656 - val_loss: 0.1173 - val_accuracy: 0.9600\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1029 - accuracy: 0.9702 - val_loss: 0.1086 - val_accuracy: 0.9653\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9735 - val_loss: 0.0989 - val_accuracy: 0.9667\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.9748 - val_loss: 0.0934 - val_accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9769 - val_loss: 0.0917 - val_accuracy: 0.9713\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9789 - val_loss: 0.0864 - val_accuracy: 0.9733\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9805 - val_loss: 0.0844 - val_accuracy: 0.9733\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9811 - val_loss: 0.0846 - val_accuracy: 0.9740\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.0799 - val_accuracy: 0.9733\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9827 - val_loss: 0.0769 - val_accuracy: 0.9773\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9837 - val_loss: 0.0751 - val_accuracy: 0.9760\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0541 - accuracy: 0.9849 - val_loss: 0.0744 - val_accuracy: 0.9773\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.0744 - val_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 0.0700 - val_accuracy: 0.9820\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.0700 - val_accuracy: 0.9813\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.9866 - val_loss: 0.0699 - val_accuracy: 0.9793\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.0688 - val_accuracy: 0.9820\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.9877 - val_loss: 0.0682 - val_accuracy: 0.9813\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.0668 - val_accuracy: 0.9813\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0675 - val_accuracy: 0.9813\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9892 - val_loss: 0.0672 - val_accuracy: 0.9820\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 0.0657 - val_accuracy: 0.9813\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.0632 - val_accuracy: 0.9847\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.0655 - val_accuracy: 0.9820\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9902 - val_loss: 0.0633 - val_accuracy: 0.9833\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 0.0638 - val_accuracy: 0.9833\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0651 - val_accuracy: 0.9827\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0650 - val_accuracy: 0.9827\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.0664 - val_accuracy: 0.9827\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9918 - val_loss: 0.0619 - val_accuracy: 0.9853\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9924 - val_loss: 0.0636 - val_accuracy: 0.9840\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9926 - val_loss: 0.0667 - val_accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.0662 - val_accuracy: 0.9860\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.0637 - val_accuracy: 0.9847\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.0608 - val_accuracy: 0.9853\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0609 - val_accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 0.0615 - val_accuracy: 0.9847\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.0600 - val_accuracy: 0.9853\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0606 - val_accuracy: 0.9860\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.0626 - val_accuracy: 0.9847\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9943 - val_loss: 0.0607 - val_accuracy: 0.9860\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0635 - val_accuracy: 0.9860\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.0587 - val_accuracy: 0.9860\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0610 - val_accuracy: 0.9860\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.0628 - val_accuracy: 0.9860\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0606 - val_accuracy: 0.9847\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.0613 - val_accuracy: 0.9867\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.0603 - val_accuracy: 0.9847\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.0614 - val_accuracy: 0.9853\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.0611 - val_accuracy: 0.9860\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.0641 - val_accuracy: 0.9867\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9952 - val_loss: 0.0593 - val_accuracy: 0.9873\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9860\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.0607 - val_accuracy: 0.9873\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.0599 - val_accuracy: 0.9847\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9959 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.0601 - val_accuracy: 0.9853\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 0.0582 - val_accuracy: 0.9853\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9960 - val_loss: 0.0593 - val_accuracy: 0.9867\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.0591 - val_accuracy: 0.9853\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.0646 - val_accuracy: 0.9880\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.0584 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.0587 - val_accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.0600 - val_accuracy: 0.9853\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.0593 - val_accuracy: 0.9867\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 0.0585 - val_accuracy: 0.9867\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 0.0581 - val_accuracy: 0.9873\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.0580 - val_accuracy: 0.9867\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.0581 - val_accuracy: 0.9867\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.0587 - val_accuracy: 0.9873\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.0574 - val_accuracy: 0.9873\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.0601 - val_accuracy: 0.9880\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.0590 - val_accuracy: 0.9873\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.0590 - val_accuracy: 0.9880\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0613 - val_accuracy: 0.9880\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.0625 - val_accuracy: 0.9880\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.0594 - val_accuracy: 0.9887\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0619 - val_accuracy: 0.9880\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9860\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0584 - val_accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0564 - val_accuracy: 0.9873\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0601 - val_accuracy: 0.9887\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0589 - val_accuracy: 0.9860\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.0634 - val_accuracy: 0.9880\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.0602 - val_accuracy: 0.9880\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0594 - val_accuracy: 0.9880\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0570 - val_accuracy: 0.9873\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9887\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0580 - val_accuracy: 0.9867\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.0609 - val_accuracy: 0.9887\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.0580 - val_accuracy: 0.9887\n",
      "Training results\n",
      "Training Accuracy: 0.9974166750907898\n",
      "Training Loss: 0.012660179287195206\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.9886666536331177\n",
      "Validation Loss: 0.05800541117787361\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_custom_model = tf.keras.Sequential(name='custom_2D_conv_model')\n",
    "my_custom_model.add(tf.keras.Input(shape=(x_train.shape[1],)))\n",
    "my_custom_model.add(tf.keras.layers.Reshape((1000,1,1),name='Reshape'))\n",
    "my_custom_model.add(tf.keras.layers.Conv2D(8,5,padding='same',activation='relu'))\n",
    "my_custom_model.add(tf.keras.layers.MaxPooling2D(2,2, padding='same'))\n",
    "my_custom_model.add(tf.keras.layers.Flatten())\n",
    "my_custom_model.add(tf.keras.layers.Dense(3,activation='softmax', name=\"output\"))\n",
    "\n",
    "\n",
    "print(my_custom_model.summary())\n",
    "my_custom_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = my_custom_model.fit(x_train, y_train ,epochs=100, validation_data=(x_val, y_val), verbose=1)   \n",
    "\n",
    "\n",
    "# Plotting accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('Model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save custom model as .tflite and .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model/assets\n",
      "2022-10-05 14:47:57.770199: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:47:57.770216: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:47:57.770291: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: my_custom_model/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52436"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 14:47:57.770988: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:47:57.771000: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: my_custom_model/\n",
      "2022-10-05 14:47:57.772797: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:47:57.787979: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: my_custom_model/\n",
      "2022-10-05 14:47:57.792075: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 21784 microseconds.\n"
     ]
    }
   ],
   "source": [
    "SAVED_MODEL = 'my_custom_model/'\n",
    "tf.saved_model.save(my_custom_model, SAVED_MODEL)\n",
    "float_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "float_tflite_model = float_converter.convert()\n",
    "tflite_model_file = pathlib.Path('my_custom_model.tflite')\n",
    "tflite_model_file.write_bytes(float_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize custom model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 14:48:01.803145: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:48:01.803164: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:48:01.803246: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: my_custom_model/\n",
      "2022-10-05 14:48:01.803926: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:48:01.803938: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: my_custom_model/\n",
      "2022-10-05 14:48:01.805764: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:48:01.821425: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: my_custom_model/\n",
      "2022-10-05 14:48:01.825737: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 22489 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16520"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_file = pathlib.Path('my_custom_model_optimized.tflite')\n",
    "tflite_model_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dense model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_20 (Flatten)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 4)                 4004      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,019\n",
      "Trainable params: 4,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/188 [..............................] - ETA: 30s - loss: 1.1205 - accuracy: 0.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/veysiadn/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step - loss: 0.7512 - accuracy: 0.6669 - val_loss: 0.5685 - val_accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8393 - val_loss: 0.4341 - val_accuracy: 0.8720\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.8959 - val_loss: 0.3243 - val_accuracy: 0.9107\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9284 - val_loss: 0.2577 - val_accuracy: 0.9280\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2318 - accuracy: 0.9421 - val_loss: 0.2187 - val_accuracy: 0.9407\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9528 - val_loss: 0.1863 - val_accuracy: 0.9467\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9601 - val_loss: 0.1728 - val_accuracy: 0.9520\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9622 - val_loss: 0.1544 - val_accuracy: 0.9553\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9648 - val_loss: 0.1456 - val_accuracy: 0.9540\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9683 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9705 - val_loss: 0.1311 - val_accuracy: 0.9587\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9725 - val_loss: 0.1221 - val_accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9731 - val_loss: 0.1196 - val_accuracy: 0.9647\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9745 - val_loss: 0.1121 - val_accuracy: 0.9667\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9756 - val_loss: 0.1090 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9768 - val_loss: 0.1055 - val_accuracy: 0.9687\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9778 - val_loss: 0.1051 - val_accuracy: 0.9667\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9785 - val_loss: 0.1003 - val_accuracy: 0.9667\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9786 - val_loss: 0.1002 - val_accuracy: 0.9713\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9804 - val_loss: 0.0971 - val_accuracy: 0.9687\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9816 - val_loss: 0.0962 - val_accuracy: 0.9693\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9811 - val_loss: 0.0947 - val_accuracy: 0.9707\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9817 - val_loss: 0.0976 - val_accuracy: 0.9700\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9827 - val_loss: 0.0914 - val_accuracy: 0.9713\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 0.0966 - val_accuracy: 0.9700\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9838 - val_loss: 0.0928 - val_accuracy: 0.9713\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9846 - val_loss: 0.0906 - val_accuracy: 0.9733\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.0913 - val_accuracy: 0.9733\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.0937 - val_accuracy: 0.9753\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.0922 - val_accuracy: 0.9773\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9856 - val_loss: 0.0882 - val_accuracy: 0.9787\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.0944 - val_accuracy: 0.9733\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9861 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9880 - val_loss: 0.0944 - val_accuracy: 0.9760\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9878 - val_loss: 0.0933 - val_accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.9883 - val_loss: 0.0956 - val_accuracy: 0.9747\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9892 - val_loss: 0.0990 - val_accuracy: 0.9773\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9886 - val_loss: 0.0916 - val_accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9901 - val_loss: 0.0884 - val_accuracy: 0.9767\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9897 - val_loss: 0.0925 - val_accuracy: 0.9753\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9897 - val_loss: 0.0898 - val_accuracy: 0.9760\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9904 - val_loss: 0.0996 - val_accuracy: 0.9727\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9911 - val_loss: 0.0958 - val_accuracy: 0.9747\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9899 - val_loss: 0.0934 - val_accuracy: 0.9793\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 0.0952 - val_accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9910 - val_loss: 0.0937 - val_accuracy: 0.9767\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9904 - val_loss: 0.0930 - val_accuracy: 0.9773\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9921 - val_loss: 0.0946 - val_accuracy: 0.9767\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9918 - val_loss: 0.0910 - val_accuracy: 0.9780\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9919 - val_loss: 0.0983 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.0938 - val_accuracy: 0.9740\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9923 - val_loss: 0.0926 - val_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9926 - val_loss: 0.0936 - val_accuracy: 0.9773\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9925 - val_loss: 0.0949 - val_accuracy: 0.9767\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9925 - val_loss: 0.0977 - val_accuracy: 0.9793\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9930 - val_loss: 0.0976 - val_accuracy: 0.9760\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9926 - val_loss: 0.1008 - val_accuracy: 0.9760\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9929 - val_loss: 0.1033 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9934 - val_loss: 0.1019 - val_accuracy: 0.9787\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9928 - val_loss: 0.1030 - val_accuracy: 0.9767\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9932 - val_loss: 0.1021 - val_accuracy: 0.9773\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9930 - val_loss: 0.1045 - val_accuracy: 0.9760\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9935 - val_loss: 0.1042 - val_accuracy: 0.9773\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9928 - val_loss: 0.1064 - val_accuracy: 0.9773\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9937 - val_loss: 0.1032 - val_accuracy: 0.9780\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.1075 - val_accuracy: 0.9773\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9934 - val_loss: 0.1100 - val_accuracy: 0.9787\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9933 - val_loss: 0.1079 - val_accuracy: 0.9773\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9929 - val_loss: 0.1079 - val_accuracy: 0.9787\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9935 - val_loss: 0.1161 - val_accuracy: 0.9753\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9942 - val_loss: 0.1112 - val_accuracy: 0.9793\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9934 - val_loss: 0.1178 - val_accuracy: 0.9773\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9942 - val_loss: 0.1156 - val_accuracy: 0.9753\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9933 - val_loss: 0.1080 - val_accuracy: 0.9773\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9945 - val_loss: 0.1293 - val_accuracy: 0.9740\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.1188 - val_accuracy: 0.9793\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9943 - val_loss: 0.1188 - val_accuracy: 0.9753\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9950 - val_loss: 0.1219 - val_accuracy: 0.9787\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9946 - val_loss: 0.1197 - val_accuracy: 0.9773\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9946 - val_loss: 0.1250 - val_accuracy: 0.9773\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9947 - val_loss: 0.1244 - val_accuracy: 0.9767\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9954 - val_loss: 0.1166 - val_accuracy: 0.9767\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9951 - val_loss: 0.1171 - val_accuracy: 0.9773\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9942 - val_loss: 0.1242 - val_accuracy: 0.9787\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9947 - val_loss: 0.1273 - val_accuracy: 0.9767\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 0.1195 - val_accuracy: 0.9767\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9957 - val_loss: 0.1336 - val_accuracy: 0.9760\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9947 - val_loss: 0.1297 - val_accuracy: 0.9740\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9953 - val_loss: 0.1373 - val_accuracy: 0.9740\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9953 - val_loss: 0.1324 - val_accuracy: 0.9760\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9944 - val_loss: 0.1405 - val_accuracy: 0.9773\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9951 - val_loss: 0.1386 - val_accuracy: 0.9780\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9949 - val_loss: 0.1357 - val_accuracy: 0.9767\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9950 - val_loss: 0.1407 - val_accuracy: 0.9767\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 0.1465 - val_accuracy: 0.9753\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9952 - val_loss: 0.1351 - val_accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9954 - val_loss: 0.1424 - val_accuracy: 0.9740\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9956 - val_loss: 0.1463 - val_accuracy: 0.9753\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9958 - val_loss: 0.1442 - val_accuracy: 0.9773\n",
      "Training results\n",
      "Training Accuracy: 0.9957500100135803\n",
      "Training Loss: 0.026185650378465652\n",
      "Evaluation results\n",
      "Validation Accuracy: 0.9773333072662354\n",
      "Validation Loss: 0.14419926702976227\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEED = 99\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "# train_dataset.unbatch()\n",
    "\n",
    "dense_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(1000,)),\n",
    "    tf.keras.layers.Dense(4, activation='swish'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "dense_model.summary()              \n",
    "\n",
    "history=dense_model.fit(train_dataset,validation_data=val_dataset, epochs=100)\n",
    "# dense_model.evaluate(val_dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('dense_model loss & accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# accuracy!\n",
    "print(\"Training results\")\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Training Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# evaluating dense_model\n",
    "print(\"Evaluation results\")\n",
    "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dense model as tflite - no optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dense_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dense_model/assets\n",
      "2022-10-05 14:50:24.003465: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:50:24.003481: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:50:24.003557: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: dense_model/\n",
      "2022-10-05 14:50:24.004204: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:50:24.004215: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: dense_model/\n",
      "2022-10-05 14:50:24.005970: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:50:24.020793: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: dense_model/\n",
      "2022-10-05 14:50:24.024649: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 21091 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18412"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL = 'dense_model/'\n",
    "tf.saved_model.save(dense_model, SAVED_MODEL)\n",
    "float_converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "float_tflite_model = float_converter.convert()\n",
    "import pathlib\n",
    "tflite_model_file = pathlib.Path('dense_model.tflite')\n",
    "tflite_model_file.write_bytes(float_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize dense model and save it as tflite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 14:50:40.147902: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-05 14:50:40.147920: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-10-05 14:50:40.147996: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: dense_model/\n",
      "2022-10-05 14:50:40.148640: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-10-05 14:50:40.148652: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: dense_model/\n",
      "2022-10-05 14:50:40.150423: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-10-05 14:50:40.165601: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: dense_model/\n",
      "2022-10-05 14:50:40.170477: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 22481 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6496"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_file = pathlib.Path('dense_model_optimized.tflite')\n",
    "tflite_model_file.write_bytes(tflite_quant_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='dense_model.tflite')\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, indices):\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = 0\n",
    "  for i, index in enumerate(indices):\n",
    "    test_data = x_test_to_use[index]\n",
    "    test_data=np.expand_dims(test_data, axis=0)\n",
    "    test_labels = y_train[index]\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    print(output[0])\n",
    "    print(output[1])\n",
    "    print(output[2])\n",
    "    predictions = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.739755e-08\n",
      "0.0001626227\n",
      "0.9998373\n",
      " Model \n",
      " True:[2], Predicted:2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "tflite_model_file = 'dense_model.tflite'\n",
    "# Change this to test a different image\n",
    "indice = 333\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, indice, model_type):\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [indice])\n",
    "\n",
    "  print(f\" Model \\n True:{y_test_to_use[indice]}, Predicted:{predictions}\")\n",
    "  \n",
    "test_model(tflite_model_file, indice, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_path='float_model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_tflite_model_for_eval(interpreter, indices):\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = 0\n",
    "  for i, index in enumerate(indices):\n",
    "    test_data = x_test_to_use[index]\n",
    "    test_data=np.expand_dims(test_data, axis=0)\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    predictions = output.argmax()\n",
    "  return predictions\n",
    "  \n",
    "def evaluate_model(interpreter):\n",
    "  output_predictions =[]\n",
    "  for i in range(len(x_test_to_use)):\n",
    "    output_predictions.append(run_tflite_model_for_eval(interpreter,[i]))\n",
    "  output_predictions = np.array(output_predictions)\n",
    "  output_predictions = np.expand_dims(output_predictions, axis=1)\n",
    "  accuracy = (output_predictions == y_test_to_use).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized dense_model TFLite test_accuracy: 0.9926666666666667\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='conv_model_paper_2D.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Optimized dense_model TFLite test_accuracy:', test_accuracy)\n",
    "# print('Quant TF test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with annotated layers for quantization -- Trial can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Quantization based training\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "# quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "# #### tf.keras.layers :\n",
    "\n",
    "# quantize_annotate_layer((tf.keras.layers.Reshape((1000,1,1),name='Reshape', input_shape=(1000,)))),\n",
    "# quantize_annotate_layer(tf.keras.layers.Conv2D(16,7,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Activation('relu')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(4,4,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Conv2D(8,5, padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Activation('relu')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(4,4,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.MaxPooling2D(2,2,padding='same')),\n",
    "# quantize_annotate_layer(tf.keras.layers.Flatten()),\n",
    "# quantize_annotate_layer(tf.keras.layers.Dense(32)),\n",
    "# quantize_annotate_layer(tf.keras.layers.Dense(3, activation='softmax')),\n",
    "# ])\n",
    "# quantized_model = tfmot.quantization.keras.quantize_apply(model)\n",
    "# # quant_aware_model = tfmot.quantization.keras.quantize_model(base_model)\n",
    "# # quant_aware_model.summary()\n",
    "# print(model.summary())\n",
    "# quantized_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = quantized_model.fit(x_train, y_train ,epochs=50, validation_data=(x_test, y_test), verbose=1)   \n",
    "\n",
    "\n",
    "# # Plotting accuracy and loss\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "# plt.title('Model loss & accuracy')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['tr_loss', 'tr_accuracy', 'val_acc', 'val_loss'], loc='lower right')\n",
    "# # accuracy!\n",
    "# print(\"Training results\")\n",
    "# print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
    "# print(f\"Loss: {history.history['loss'][-1]}\")\n",
    "\n",
    "# # evaluating model\n",
    "# print(\"Evaluation results\")\n",
    "# print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "# print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41e74be16d15307d9f039f42bdba433d4433ec6233894682bf41214f89ea7b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
