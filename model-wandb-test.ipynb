{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Download Acustic Emission Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:33:22.748100Z","iopub.status.busy":"2022-10-10T21:33:22.747770Z","iopub.status.idle":"2022-10-10T21:33:30.435488Z","shell.execute_reply":"2022-10-10T21:33:30.434382Z","shell.execute_reply.started":"2022-10-10T21:33:22.748067Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1LIkyqBeKWk5GHyiuVL-lUBA-JD7g5omA\n","To: /kaggle/working/matlab15000.mat\n","100%|██████████| 105M/105M [00:00<00:00, 136MB/s]  \n"]},{"data":{"text/plain":["'matlab15000.mat'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import gdown\n","## While creating link, select anyone with the link, and additionally, uc?id= should be added like in below.\n","url = 'https://drive.google.com/uc?id=1LIkyqBeKWk5GHyiuVL-lUBA-JD7g5omA'\n","output = 'matlab15000.mat'\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Use GPU and import necessary libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:33:30.437868Z","iopub.status.busy":"2022-10-10T21:33:30.437472Z","iopub.status.idle":"2022-10-10T21:33:38.826340Z","shell.execute_reply":"2022-10-10T21:33:38.825164Z","shell.execute_reply.started":"2022-10-10T21:33:30.437831Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","# Veysi ADIN 19 SEPT 2022\n","from pandas import read_csv\n","from numpy import set_printoptions\n","from sklearn import datasets, linear_model\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.model_selection import train_test_split\n","import random\n","# Using GPU\n","import os\n","import scipy.io as scpy\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","cpus = tf.config.experimental.list_physical_devices('CPU')\n","\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n","elif cpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n","        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Login wandb interface with API key"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:33:48.010583Z","iopub.status.busy":"2022-10-10T21:33:48.010108Z","iopub.status.idle":"2022-10-10T21:33:50.414404Z","shell.execute_reply":"2022-10-10T21:33:50.413265Z","shell.execute_reply.started":"2022-10-10T21:33:48.010535Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.login(key='0eeb933c285c4fbafee9f8d0f3d524022593e894')"]},{"cell_type":"markdown","metadata":{},"source":["### Load dataset and split it 80,10,10 for train,validation and test"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:33:50.417023Z","iopub.status.busy":"2022-10-10T21:33:50.415927Z","iopub.status.idle":"2022-10-10T21:33:51.410368Z","shell.execute_reply":"2022-10-10T21:33:51.409441Z","shell.execute_reply.started":"2022-10-10T21:33:50.416980Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(15000, 1000)\n","(15000, 1)\n"," (12000, 1500, 1500)\n"]}],"source":["data = scpy.loadmat(\"matlab15000.mat\")\n","# Extracting x_train from the mat file dictionary.\n","x_data = data[\"XTrain\"]\n","# Extracting y_train from the mat file dictionary.\n","y_data = data[\"unnamed\"]\n","# Converting x_train and y_train to a numpy array.\n","x_data = np.array(x_data,dtype='float32')\n","y_train = np.array(y_data,dtype='float32')\n","# Verifying the shapes.\n","print(x_data.shape)\n","print(y_data.shape)\n","\n","SEED = 99\n","os.environ['PYTHONHASHSEED']=str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","# split into train test sets\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=SEED)\n","\n","\n","x_val = x_test[:1500]\n","y_val = y_test[:1500]\n","x_test_to_use = x_test[1500:]\n","y_test_to_use = y_test[1500:]\n","print(f\" {len(x_train), len(x_val), len(x_test_to_use)}\")\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","BATCH_SIZE = 64\n","# SHUFFLE_BUFFER_SIZE = 100\n","train_dataset = train_dataset.batch(BATCH_SIZE)\n","test_dataset = test_dataset.batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:37:03.498454Z","iopub.status.busy":"2022-10-10T21:37:03.497277Z","iopub.status.idle":"2022-10-10T21:37:03.505038Z","shell.execute_reply":"2022-10-10T21:37:03.503697Z","shell.execute_reply.started":"2022-10-10T21:37:03.498408Z"},"trusted":true},"outputs":[],"source":["def train_step(x, y, model, optimizer, loss_fn, train_acc_metric):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","    train_acc_metric.update_state(y, logits)\n","\n","    return loss_value"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:37:05.603082Z","iopub.status.busy":"2022-10-10T21:37:05.602119Z","iopub.status.idle":"2022-10-10T21:37:05.608511Z","shell.execute_reply":"2022-10-10T21:37:05.607486Z","shell.execute_reply.started":"2022-10-10T21:37:05.603038Z"},"trusted":true},"outputs":[],"source":["def test_step(x, y, model, loss_fn, val_acc_metric):\n","    val_logits = model(x, training=False)\n","    loss_value = loss_fn(y, val_logits)\n","    val_acc_metric.update_state(y, val_logits)\n","\n","    return loss_value"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:37:08.134901Z","iopub.status.busy":"2022-10-10T21:37:08.134109Z","iopub.status.idle":"2022-10-10T21:37:08.145155Z","shell.execute_reply":"2022-10-10T21:37:08.143949Z","shell.execute_reply.started":"2022-10-10T21:37:08.134862Z"},"trusted":true},"outputs":[],"source":["def train(train_dataset, val_dataset,  model, optimizer,\n","          train_acc_metric, val_acc_metric,\n","          epochs=10,  log_step=200, val_log_step=50):\n","  \n","    for epoch in range(epochs):\n","        print(\"\\nStart of epoch %d\" % (epoch,))\n","\n","        train_loss = []   \n","        val_loss = []\n","\n","        # Iterate over the batches of the dataset\n","        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","            loss_value = train_step(x_batch_train, y_batch_train, \n","                                    model, optimizer, \n","                                    loss_fn, train_acc_metric)\n","            train_loss.append(float(loss_value))\n","\n","        # Run a validation loop at the end of each epoch\n","        for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n","            val_loss_value = test_step(x_batch_val, y_batch_val, \n","                                       model, loss_fn, \n","                                       val_acc_metric)\n","            val_loss.append(float(val_loss_value))\n","            \n","        # Display metrics at the end of each epoch\n","        train_acc = train_acc_metric.result()\n","        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","        val_acc = val_acc_metric.result()\n","        print(\"Validation acc: %.4f\" % (float(val_acc),))\n","\n","        # Reset metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","        val_acc_metric.reset_states()\n","\n","        # ⭐: log metrics using wandb.log\n","        wandb.log({'epochs': epoch,\n","                   'loss': np.mean(train_loss),\n","                   'acc': float(train_acc), \n","                   'val_loss': np.mean(val_loss),\n","                   'val_acc':float(val_acc)})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_conv_model():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Reshape((1000,1,1),name='Reshape')(inputs)\n","    x2 = tf.keras.layers.Conv2D(8,5,padding='same')(x1)\n","    x3= tf.keras.layers.Activation('relu')(x2)\n","    x4 = tf.keras.layers.MaxPooling2D(2,2, padding='same')(x3)\n","    x5 = tf.keras.layers.Flatten()(x4)\n","    outputs = tf.keras.layers.Dense(3,activation='softmax', name=\"output\")(x5)\n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_conv_model_paper():\n","    inputs=keras.Input(shape=(x_train.shape[1],))\n","    x0 = tf.keras.layers.Reshape((1000,1),name='Reshape')(inputs)\n","    x1=tf.keras.layers.Conv1D(32,7)(x0)\n","    x2=tf.keras.layers.BatchNormalization()(x1)\n","    x3=tf.keras.layers.Activation('relu')(x2)\n","    x4=tf.keras.layers.MaxPooling1D(pool_size=8)(x3)\n","    x5=tf.keras.layers.Conv1D(48,5)(x4)\n","    x6=tf.keras.layers.BatchNormalization()(x5)\n","    x7=tf.keras.layers.Activation('relu')(x6)\n","    x8=tf.keras.layers.MaxPooling1D(pool_size=4)(x7)\n","    x9=tf.keras.layers.MaxPooling1D(pool_size=4)(x8)\n","    x10=tf.keras.layers.Dropout(0.3)(x9)\n","    x11=tf.keras.layers.Flatten()(x10)\n","    x12=tf.keras.layers.Dense(32)(x11)\n","    x13=tf.keras.layers.Dense(32)(x12)\n","    outputs=tf.keras.layers.Dense(3, activation='softmax')(x13)\n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"relu\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_swish():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"swish\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","\n","def make_dense_model_tanh():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"tanh\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_elu():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"elu\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_gelu():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"gelu\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_plus():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"softplus\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_hard_sigmoid():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"hard_sigmoid\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_model_sigmoid():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"sigmoid\")(x1)\n","    outputs = keras.layers.Dense(3, name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_act_sigmoid():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"elu\")(x1)\n","    outputs = keras.layers.Dense(3, activation='sigmoid',name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)\n","def make_dense_act_softmax():\n","    inputs = keras.Input(shape=(x_train.shape[1],))\n","    x1 = tf.keras.layers.Flatten(input_shape=(1000,))(inputs)\n","    x2 = keras.layers.Dense(4, activation=\"sigmoid\")(x1)\n","    outputs = keras.layers.Dense(3, activation='softmax',name=\"output\")(x2)\n","    \n","    return keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-10-10T21:52:42.456406Z","iopub.status.busy":"2022-10-10T21:52:42.456038Z","iopub.status.idle":"2022-10-10T21:56:33.086094Z","shell.execute_reply":"2022-10-10T21:56:33.085167Z","shell.execute_reply.started":"2022-10-10T21:52:42.456373Z"},"trusted":true},"outputs":[{"data":{"text/html":["wandb version 0.13.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.12.21"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20221010_215242-2m4nuh16</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/veysiadn/dense-model-activations-fixed-seed/runs/2m4nuh16\" target=\"_blank\">Act-Softmax-Logist-True</a></strong> to <a href=\"https://wandb.ai/veysiadn/dense-model-activations-fixed-seed\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 1000)]            0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 1000)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 4004      \n","_________________________________________________________________\n","output (Dense)               (None, 3)                 15        \n","=================================================================\n","Total params: 4,019\n","Trainable params: 4,019\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Start of epoch 0\n","Training acc over epoch: 0.7479\n","Validation acc: 0.8413\n","\n","Start of epoch 1\n","Training acc over epoch: 0.8950\n","Validation acc: 0.9153\n","\n","Start of epoch 2\n","Training acc over epoch: 0.9420\n","Validation acc: 0.9493\n","\n","Start of epoch 3\n","Training acc over epoch: 0.9623\n","Validation acc: 0.9680\n","\n","Start of epoch 4\n","Training acc over epoch: 0.9712\n","Validation acc: 0.9740\n","\n","Start of epoch 5\n","Training acc over epoch: 0.9772\n","Validation acc: 0.9767\n","\n","Start of epoch 6\n","Training acc over epoch: 0.9805\n","Validation acc: 0.9787\n","\n","Start of epoch 7\n","Training acc over epoch: 0.9838\n","Validation acc: 0.9793\n","\n","Start of epoch 8\n","Training acc over epoch: 0.9858\n","Validation acc: 0.9787\n","\n","Start of epoch 9\n","Training acc over epoch: 0.9867\n","Validation acc: 0.9793\n","\n","Start of epoch 10\n","Training acc over epoch: 0.9877\n","Validation acc: 0.9807\n","\n","Start of epoch 11\n","Training acc over epoch: 0.9887\n","Validation acc: 0.9833\n","\n","Start of epoch 12\n","Training acc over epoch: 0.9900\n","Validation acc: 0.9840\n","\n","Start of epoch 13\n","Training acc over epoch: 0.9911\n","Validation acc: 0.9853\n","\n","Start of epoch 14\n","Training acc over epoch: 0.9913\n","Validation acc: 0.9853\n","\n","Start of epoch 15\n","Training acc over epoch: 0.9921\n","Validation acc: 0.9853\n","\n","Start of epoch 16\n","Training acc over epoch: 0.9927\n","Validation acc: 0.9853\n","\n","Start of epoch 17\n","Training acc over epoch: 0.9931\n","Validation acc: 0.9853\n","\n","Start of epoch 18\n","Training acc over epoch: 0.9934\n","Validation acc: 0.9853\n","\n","Start of epoch 19\n","Training acc over epoch: 0.9937\n","Validation acc: 0.9840\n","\n","Start of epoch 20\n","Training acc over epoch: 0.9937\n","Validation acc: 0.9847\n","\n","Start of epoch 21\n","Training acc over epoch: 0.9938\n","Validation acc: 0.9833\n","\n","Start of epoch 22\n","Training acc over epoch: 0.9942\n","Validation acc: 0.9833\n","\n","Start of epoch 23\n","Training acc over epoch: 0.9946\n","Validation acc: 0.9840\n","\n","Start of epoch 24\n","Training acc over epoch: 0.9950\n","Validation acc: 0.9833\n","\n","Start of epoch 25\n","Training acc over epoch: 0.9949\n","Validation acc: 0.9833\n","\n","Start of epoch 26\n","Training acc over epoch: 0.9954\n","Validation acc: 0.9833\n","\n","Start of epoch 27\n","Training acc over epoch: 0.9956\n","Validation acc: 0.9833\n","\n","Start of epoch 28\n","Training acc over epoch: 0.9959\n","Validation acc: 0.9833\n","\n","Start of epoch 29\n","Training acc over epoch: 0.9959\n","Validation acc: 0.9833\n","\n","Start of epoch 30\n","Training acc over epoch: 0.9958\n","Validation acc: 0.9827\n","\n","Start of epoch 31\n","Training acc over epoch: 0.9959\n","Validation acc: 0.9827\n","\n","Start of epoch 32\n","Training acc over epoch: 0.9959\n","Validation acc: 0.9827\n","\n","Start of epoch 33\n","Training acc over epoch: 0.9960\n","Validation acc: 0.9833\n","\n","Start of epoch 34\n","Training acc over epoch: 0.9962\n","Validation acc: 0.9840\n","\n","Start of epoch 35\n","Training acc over epoch: 0.9965\n","Validation acc: 0.9833\n","\n","Start of epoch 36\n","Training acc over epoch: 0.9966\n","Validation acc: 0.9840\n","\n","Start of epoch 37\n","Training acc over epoch: 0.9967\n","Validation acc: 0.9833\n","\n","Start of epoch 38\n","Training acc over epoch: 0.9968\n","Validation acc: 0.9833\n","\n","Start of epoch 39\n","Training acc over epoch: 0.9967\n","Validation acc: 0.9840\n","\n","Start of epoch 40\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9840\n","\n","Start of epoch 41\n","Training acc over epoch: 0.9968\n","Validation acc: 0.9840\n","\n","Start of epoch 42\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9847\n","\n","Start of epoch 43\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9847\n","\n","Start of epoch 44\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9860\n","\n","Start of epoch 45\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9847\n","\n","Start of epoch 46\n","Training acc over epoch: 0.9970\n","Validation acc: 0.9847\n","\n","Start of epoch 47\n","Training acc over epoch: 0.9972\n","Validation acc: 0.9833\n","\n","Start of epoch 48\n","Training acc over epoch: 0.9971\n","Validation acc: 0.9833\n","\n","Start of epoch 49\n","Training acc over epoch: 0.9972\n","Validation acc: 0.9833\n","\n","Start of epoch 50\n","Training acc over epoch: 0.9974\n","Validation acc: 0.9827\n","\n","Start of epoch 51\n","Training acc over epoch: 0.9973\n","Validation acc: 0.9807\n","\n","Start of epoch 52\n","Training acc over epoch: 0.9974\n","Validation acc: 0.9807\n","\n","Start of epoch 53\n","Training acc over epoch: 0.9977\n","Validation acc: 0.9820\n","\n","Start of epoch 54\n","Training acc over epoch: 0.9979\n","Validation acc: 0.9813\n","\n","Start of epoch 55\n","Training acc over epoch: 0.9978\n","Validation acc: 0.9813\n","\n","Start of epoch 56\n","Training acc over epoch: 0.9980\n","Validation acc: 0.9813\n","\n","Start of epoch 57\n","Training acc over epoch: 0.9980\n","Validation acc: 0.9833\n","\n","Start of epoch 58\n","Training acc over epoch: 0.9981\n","Validation acc: 0.9827\n","\n","Start of epoch 59\n","Training acc over epoch: 0.9978\n","Validation acc: 0.9833\n","\n","Start of epoch 60\n","Training acc over epoch: 0.9982\n","Validation acc: 0.9827\n","\n","Start of epoch 61\n","Training acc over epoch: 0.9978\n","Validation acc: 0.9820\n","\n","Start of epoch 62\n","Training acc over epoch: 0.9979\n","Validation acc: 0.9820\n","\n","Start of epoch 63\n","Training acc over epoch: 0.9979\n","Validation acc: 0.9813\n","\n","Start of epoch 64\n","Training acc over epoch: 0.9982\n","Validation acc: 0.9827\n","\n","Start of epoch 65\n","Training acc over epoch: 0.9983\n","Validation acc: 0.9813\n","\n","Start of epoch 66\n","Training acc over epoch: 0.9982\n","Validation acc: 0.9800\n","\n","Start of epoch 67\n","Training acc over epoch: 0.9984\n","Validation acc: 0.9840\n","\n","Start of epoch 68\n","Training acc over epoch: 0.9983\n","Validation acc: 0.9800\n","\n","Start of epoch 69\n","Training acc over epoch: 0.9985\n","Validation acc: 0.9800\n","\n","Start of epoch 70\n","Training acc over epoch: 0.9984\n","Validation acc: 0.9813\n","\n","Start of epoch 71\n","Training acc over epoch: 0.9983\n","Validation acc: 0.9800\n","\n","Start of epoch 72\n","Training acc over epoch: 0.9983\n","Validation acc: 0.9807\n","\n","Start of epoch 73\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9787\n","\n","Start of epoch 74\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9787\n","\n","Start of epoch 75\n","Training acc over epoch: 0.9986\n","Validation acc: 0.9813\n","\n","Start of epoch 76\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9793\n","\n","Start of epoch 77\n","Training acc over epoch: 0.9986\n","Validation acc: 0.9787\n","\n","Start of epoch 78\n","Training acc over epoch: 0.9983\n","Validation acc: 0.9780\n","\n","Start of epoch 79\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9800\n","\n","Start of epoch 80\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9807\n","\n","Start of epoch 81\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9760\n","\n","Start of epoch 82\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9793\n","\n","Start of epoch 83\n","Training acc over epoch: 0.9990\n","Validation acc: 0.9780\n","\n","Start of epoch 84\n","Training acc over epoch: 0.9990\n","Validation acc: 0.9773\n","\n","Start of epoch 85\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9800\n","\n","Start of epoch 86\n","Training acc over epoch: 0.9989\n","Validation acc: 0.9773\n","\n","Start of epoch 87\n","Training acc over epoch: 0.9990\n","Validation acc: 0.9800\n","\n","Start of epoch 88\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9780\n","\n","Start of epoch 89\n","Training acc over epoch: 0.9986\n","Validation acc: 0.9780\n","\n","Start of epoch 90\n","Training acc over epoch: 0.9989\n","Validation acc: 0.9787\n","\n","Start of epoch 91\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9787\n","\n","Start of epoch 92\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9807\n","\n","Start of epoch 93\n","Training acc over epoch: 0.9990\n","Validation acc: 0.9813\n","\n","Start of epoch 94\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9793\n","\n","Start of epoch 95\n","Training acc over epoch: 0.9987\n","Validation acc: 0.9807\n","\n","Start of epoch 96\n","Training acc over epoch: 0.9991\n","Validation acc: 0.9807\n","\n","Start of epoch 97\n","Training acc over epoch: 0.9988\n","Validation acc: 0.9787\n","\n","Start of epoch 98\n","Training acc over epoch: 0.9992\n","Validation acc: 0.9787\n","\n","Start of epoch 99\n","Training acc over epoch: 0.9992\n","Validation acc: 0.9813\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>epochs</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▆██████████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.99917</td></tr><tr><td>epochs</td><td>99</td></tr><tr><td>loss</td><td>0.00746</td></tr><tr><td>val_acc</td><td>0.98133</td></tr><tr><td>val_loss</td><td>0.12146</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">Act-Softmax-Logist-True</strong>: <a href=\"https://wandb.ai/veysiadn/dense-model-activations-fixed-seed/runs/2m4nuh16\" target=\"_blank\">https://wandb.ai/veysiadn/dense-model-activations-fixed-seed/runs/2m4nuh16</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20221010_215242-2m4nuh16/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config,group='Activations',name='Act-Softmax-Logist-True')\n","config = wandb.config\n","\n","# Initialize model.\n","model = make_dense_act_softmax()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:08:13.535335Z","iopub.status.busy":"2022-10-08T22:08:13.534940Z","iopub.status.idle":"2022-10-08T22:12:04.533339Z","shell.execute_reply":"2022-10-08T22:12:04.532422Z","shell.execute_reply.started":"2022-10-08T22:08:13.535294Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config,  group='RMSprop_L1e-3',name='Dense_Model_Sigmoid')\n","config = wandb.config\n","\n","# Initialize model.\n","# make_dense_model_elu()\n","# make_dense_model_gelu\n","# make_dense_model_plus\n","# make_dense_model_hard_sigmoid\n","# make_dense_model_sigmoid\n","\n","model = make_dense_model_sigmoid()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:12:04.536536Z","iopub.status.busy":"2022-10-08T22:12:04.535445Z","iopub.status.idle":"2022-10-08T22:16:03.572891Z","shell.execute_reply":"2022-10-08T22:16:03.571786Z","shell.execute_reply.started":"2022-10-08T22:12:04.536494Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config,  group='RMSprop_L1e-3', name='Dense_Model_Hard_Sigmoid')\n","config = wandb.config\n","\n","# Initialize model.\n","# make_dense_model_elu()\n","# make_dense_model_gelu\n","# make_dense_model_plus\n","# make_dense_model_hard_sigmoid\n","# make_dense_model_sigmoid\n","\n","model = make_dense_model_hard_sigmoid()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:16:03.575275Z","iopub.status.busy":"2022-10-08T22:16:03.574896Z","iopub.status.idle":"2022-10-08T22:19:52.473204Z","shell.execute_reply":"2022-10-08T22:19:52.472256Z","shell.execute_reply.started":"2022-10-08T22:16:03.575233Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config, group='RMSprop_L1e-3', name='Dense_Model_Sigmoid_Plus')\n","config = wandb.config\n","\n","# Initialize model.\n","# make_dense_model_elu()\n","# make_dense_model_gelu\n","# make_dense_model_plus\n","\n","model = make_dense_model_plus()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:19:52.475527Z","iopub.status.busy":"2022-10-08T22:19:52.474834Z","iopub.status.idle":"2022-10-08T22:24:01.411332Z","shell.execute_reply":"2022-10-08T22:24:01.410399Z","shell.execute_reply.started":"2022-10-08T22:19:52.475484Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config, group='RMSprop_L1e-3', name='Dense_Model_Gelu')\n","config = wandb.config\n","\n","# Initialize model.\n","# make_dense_model_elu()\n","\n","model = make_dense_model_gelu()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:24:01.414992Z","iopub.status.busy":"2022-10-08T22:24:01.414690Z","iopub.status.idle":"2022-10-08T22:27:49.449238Z","shell.execute_reply":"2022-10-08T22:27:49.448068Z","shell.execute_reply.started":"2022-10-08T22:24:01.414962Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config, group='RMSprop_L1e-3', name='Dense_Model_Elu')\n","config = wandb.config\n","\n","# Initialize model.\n","# make_dense_model_elu()\n","\n","model = make_dense_model_elu()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-10-08T22:27:49.451729Z","iopub.status.busy":"2022-10-08T22:27:49.451059Z","iopub.status.idle":"2022-10-08T22:31:42.200831Z","shell.execute_reply":"2022-10-08T22:31:42.199947Z","shell.execute_reply.started":"2022-10-08T22:27:49.451687Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config, group='RMSprop_L1e-3', name='Dense_Model_Relu')\n","config = wandb.config\n","\n","\n","model = make_dense_model()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T22:31:42.203838Z","iopub.status.busy":"2022-10-08T22:31:42.203530Z","iopub.status.idle":"2022-10-08T22:35:41.190121Z","shell.execute_reply":"2022-10-08T22:35:41.189203Z","shell.execute_reply.started":"2022-10-08T22:31:42.203810Z"},"trusted":true},"outputs":[],"source":["# initialize wandb with your project name and optionally with configutations.\n","# play around with the config values and see the result on your wandb dashboard.\n","config = {\n","              \"learning_rate\": 0.001,\n","              \"epochs\": 100,\n","              \"batch_size\": 64,\n","              \"log_step\": 200,\n","              \"val_log_step\": 50,\n","           }\n","\n","run = wandb.init(project='dense-model-activations-fixed-seed', config=config, group='RMSprop_L1e-3', name='Dense_Model_Swish')\n","config = wandb.config\n","\n","\n","model = make_dense_model_swish()\n","model.summary()\n","# Instantiate an optimizer to train the model.\n","optimizer = keras.optimizers.RMSprop(learning_rate=config.learning_rate)\n","# Instantiate a loss function.\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","train(train_dataset,\n","      test_dataset, \n","      model,\n","      optimizer,\n","      train_acc_metric,\n","      val_acc_metric,\n","      epochs=config.epochs, \n","      log_step=config.log_step, \n","      val_log_step=config.val_log_step)\n","\n","run.finish()  # In Jupyter/Colab, let us know you're finished!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
